{"id": "http://arxiv.org/abs/2508.14890v1", "title": "Estimating Initial Mass of Gaia-Enceladus Dwarf Galaxy with Chemical Evolution Model", "authors": ["Olcay Plevne", "Furkan Akbaba"], "summary": "This work investigates the initial mass and chemical evolution history of the\nGaia-Enceladus dwarf galaxy. We combine spectroscopic data from APOGEE with\nastrometric data from Gaia DR3 to identify Gaia-Enceladus candidate stars via a\nmachine-learning pipeline using t-SNE and HDBSCAN. By focusing on kinematic and\nchemical parameters, especially $\\mathrm{[Fe/H]}$, $\\mathrm{[Mg/Fe]}$,\n$\\mathrm{[Al/Fe]}$, and $\\mathrm{[Mn/Fe]}$, we uncover a population of\nmetal-poor, high-eccentricity stars that align with literature criteria for\nGaia-Enceladus debris. We then apply the \\textit{OMEGA+} chemical evolution\nmodel, incorporating MCMC fitting of the observed abundance trends in the\n$\\mathrm{[Mg/Fe]\\times[Fe/H]}$ plane. Our best-fitting model indicates a gas\nmass of $4.93_{-0.72}^{+0.32}\\times10^9\\,{M_{\\odot}}$ for Gaia-Enceladus,\nplacing it at the higher end of previously suggested mass ranges. The model\nscenario suggests a short star formation timescale, substantial outflows, and a\nrapid build-up of metals mainly driven by core-collapse supernovae, with a\nlesser contribution from Type~Ia supernovae. Comparison with observational data\nin other chemical planes (e.g., $\\mathrm{[Mg/Mn]\\times[Al/Fe]}$) supports this\nscenario, emphasizing a distinct evolution path relative to the Milky Way.\nAdditionally, our results provide indirect evidence that star formation in\nGaia-Enceladus likely ceased within the first 4 Gyr, consistent with earlier\ninferences of an early merger event. These findings highlight the power of\nchemical evolution modeling in reconstructing the origin and mass of ancient\naccreted systems. Overall, we show that Gaia-Enceladus, through a rapid star\nformation and strong outflows, contributed a significant fraction of the\nmetal-poor stellar halo of the Milky Way.", "published": "2025-08-20T17:59:01+00:00", "updated": "2025-08-20T17:59:01+00:00", "primary_category": "astro-ph.GA", "categories": ["astro-ph.GA"], "pdf_url": "http://arxiv.org/pdf/2508.14890v1"}
{"id": "http://arxiv.org/abs/2508.14889v1", "title": "MS-CLR: Multi-Skeleton Contrastive Learning for Human Action Recognition", "authors": ["Mert Kiray", "Alvaro Ritter", "Nassir Navab", "Benjamin Busam"], "summary": "Contrastive learning has gained significant attention in skeleton-based\naction recognition for its ability to learn robust representations from\nunlabeled data. However, existing methods rely on a single skeleton convention,\nwhich limits their ability to generalize across datasets with diverse joint\nstructures and anatomical coverage. We propose Multi-Skeleton Contrastive\nLearning (MS-CLR), a general self-supervised framework that aligns pose\nrepresentations across multiple skeleton conventions extracted from the same\nsequence. This encourages the model to learn structural invariances and capture\ndiverse anatomical cues, resulting in more expressive and generalizable\nfeatures. To support this, we adapt the ST-GCN architecture to handle skeletons\nwith varying joint layouts and scales through a unified representation scheme.\nExperiments on the NTU RGB+D 60 and 120 datasets demonstrate that MS-CLR\nconsistently improves performance over strong single-skeleton contrastive\nlearning baselines. A multi-skeleton ensemble further boosts performance,\nsetting new state-of-the-art results on both datasets.", "published": "2025-08-20T17:58:03+00:00", "updated": "2025-08-20T17:58:03+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14889v1"}
{"id": "http://arxiv.org/abs/2508.14884v1", "title": "Deep Reinforcement Learning Based Routing for Heterogeneous Multi-Hop Wireless Networks", "authors": ["Brian Kim", "Justin H. Kong", "Terrence J. Moore", "Fikadu T. Dagefu"], "summary": "Routing in multi-hop wireless networks is a complex problem, especially in\nheterogeneous networks where multiple wireless communication technologies\ncoexist. Reinforcement learning (RL) methods, such as Q-learning, have been\nintroduced for decentralized routing by allowing nodes to make decisions based\non local observations. However, Q-learning suffers from scalability issues and\npoor generalization due to the difficulty in managing the Q-table in large or\ndynamic network topologies, especially in heterogeneous networks (HetNets) with\ndiverse channel characteristics. Thus, in this paper, we propose a novel deep\nQ-network (DQN)-based routing framework for heterogeneous multi-hop wireless\nnetworks to maximize the end-to-end rate of the route by improving scalability\nand adaptability, where each node uses a deep neural network (DNN) to estimate\nthe Q-values and jointly select the next-hop relay and a communication\ntechnology for transmission. To achieve better performance with the DNN,\nselecting which nodes to exchange information is critical, as it not only\ndefines the state and action spaces but also determines the input to the DNN.\nTo this end, we propose neighbor node selection strategies based on channel\ngain and rate between nodes rather than a simple distance-based approach for an\nimproved set of states and actions for DQN-based routing. During training, the\nmodel experiences diverse network topologies to ensure generalization and\nrobustness, and simulation results show that the proposed neighbor node\nselection outperforms simple distance-based selection. Further, we observe that\nthe DQN-based approach outperforms various benchmark schemes and performs\ncomparably to the optimal approach.", "published": "2025-08-20T17:54:43+00:00", "updated": "2025-08-20T17:54:43+00:00", "primary_category": "eess.SP", "categories": ["eess.SP"], "pdf_url": "http://arxiv.org/pdf/2508.14884v1"}
{"id": "http://arxiv.org/abs/2508.14883v1", "title": "The Cost Advantage of Virtual Machine Migrations: Empirical Insights into Amazon's EC2 Marketspace", "authors": ["Benedikt Pittl", "Werner Mach", "Erich Schikuta"], "summary": "In recent years, cloud providers have introduced novel approaches for trading\nvirtual machines. For example, Virtustream introduced so-called muVMs to charge\ncloud computing resources while other providers such as Google, Microsoft, or\nAmazon re-invented their marketspaces. Today, the market leader Amazon runs six\nmarketspaces for trading virtual machines. Consumers can purchase bundles of\nvirtual machines, which are called cloud-portfolios, from multiple marketspaces\nand providers. An industry-relevant field of research is to identify best\npractices and guidelines on how such optimal portfolios are created. In the\npaper at hand, a cost analysis of cloud portfolios is presented. Therefore,\npricing data from Amazon was used as well as a real virtual machine utilization\ndataset from the Bitbrains datacenter. The results show that a cost optimum can\nonly be reached if heterogeneous portfolios are created where virtual machines\nare purchased from different marketspaces. Additionally, the cost-benefit of\nmigrating virtual machines to different marketplaces during runtime is\npresented. Such migrations are especially cost-effective for virtual machines\nof cloud-portfolios which run between 6 hours and 1 year. The paper further\nshows that most of the resources of virtual machines are never utilized by\nconsumers, which represents a significant future potential for cost\noptimization. For the validation of the results, a second dataset of the\nBitbrains datacenter was used, which contains utility data of virtual machines\nfrom a different domain of application.", "published": "2025-08-20T17:54:41+00:00", "updated": "2025-08-20T17:54:41+00:00", "primary_category": "cs.DC", "categories": ["cs.DC", "cs.GT", "91-08", "J.1; H.1.m"], "pdf_url": "http://arxiv.org/pdf/2508.14883v1"}
{"id": "http://arxiv.org/abs/2508.14881v1", "title": "Compute-Optimal Scaling for Value-Based Deep RL", "authors": ["Preston Fu", "Oleh Rybkin", "Zhiyuan Zhou", "Michal Nauman", "Pieter Abbeel", "Sergey Levine", "Aviral Kumar"], "summary": "As models grow larger and training them becomes expensive, it becomes\nincreasingly important to scale training recipes not just to larger models and\nmore data, but to do so in a compute-optimal manner that extracts maximal\nperformance per unit of compute. While such scaling has been well studied for\nlanguage modeling, reinforcement learning (RL) has received less attention in\nthis regard. In this paper, we investigate compute scaling for online,\nvalue-based deep RL. These methods present two primary axes for compute\nallocation: model capacity and the update-to-data (UTD) ratio. Given a fixed\ncompute budget, we ask: how should resources be partitioned across these axes\nto maximize sample efficiency? Our analysis reveals a nuanced interplay between\nmodel size, batch size, and UTD. In particular, we identify a phenomenon we\ncall TD-overfitting: increasing the batch quickly harms Q-function accuracy for\nsmall models, but this effect is absent in large models, enabling effective use\nof large batch size at scale. We provide a mental model for understanding this\nphenomenon and build guidelines for choosing batch size and UTD to optimize\ncompute usage. Our findings provide a grounded starting point for\ncompute-optimal scaling in deep RL, mirroring studies in supervised learning\nbut adapted to TD learning.", "published": "2025-08-20T17:54:21+00:00", "updated": "2025-08-20T17:54:21+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14881v1"}
{"id": "http://arxiv.org/abs/2508.14880v1", "title": "MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework", "authors": ["Ailing Yu", "Lan Yao", "Jingnan Liu", "Zhe Chen", "Jiajun Yin", "Yuan Wang", "Xinhao Liao", "Zhiling Ye", "Ji Li", "Yun Yue", "Hansong Xiao", "Hualei Zhou", "Chunxiao Guo", "Peng Wei", "Jinjie Gu"], "summary": "Recent developments in Large Language Model (LLM)-based agents have shown\nimpressive capabilities spanning multiple domains, exemplified by deep research\nsystems that demonstrate superior performance on complex information-seeking\nand synthesis tasks. While general-purpose deep research agents have shown\nimpressive capabilities, they struggle significantly with medical domain\nchallenges, as evidenced by leading proprietary systems achieving limited\naccuracy on complex medical benchmarks. The key limitations are: (1) the model\nlacks sufficient dense medical knowledge for clinical reasoning, and (2) the\nframework is constrained by the absence of specialized retrieval tools tailored\nfor medical contexts.We present a medical deep research agent that addresses\nthese challenges through two core innovations. First, we develop a novel data\nsynthesis framework using medical knowledge graphs, extracting the longest\nchains from subgraphs around rare medical entities to generate complex\nmulti-hop question-answer pairs. Second, we integrate a custom-built private\nmedical retrieval engine alongside general-purpose tools, enabling accurate\nmedical information synthesis. Our approach generates 2100+ diverse\ntrajectories across 12 medical specialties, each averaging 4.2 tool\ninteractions.Through a two-stage training paradigm combining supervised\nfine-tuning and online reinforcement learning with composite rewards, our\nMedResearcher-R1-32B model demonstrates exceptional performance, establishing\nnew state-of-the-art results on medical benchmarks while maintaining\ncompetitive performance on general deep research tasks. Our work demonstrates\nthat strategic domain-specific innovations in architecture, tool design, and\ntraining data construction can enable smaller open-source models to outperform\nmuch larger proprietary systems in specialized domains.", "published": "2025-08-20T17:51:20+00:00", "updated": "2025-08-20T17:51:20+00:00", "primary_category": "cs.CL", "categories": ["cs.CL"], "pdf_url": "http://arxiv.org/pdf/2508.14880v1"}
{"id": "http://arxiv.org/abs/2508.14871v1", "title": "Squeezed Diffusion Models", "authors": ["Jyotirmai Singh", "Samar Khanna", "James Burgess"], "summary": "Diffusion models typically inject isotropic Gaussian noise, disregarding\nstructure in the data. Motivated by the way quantum squeezed states\nredistribute uncertainty according to the Heisenberg uncertainty principle, we\nintroduce Squeezed Diffusion Models (SDM), which scale noise anisotropically\nalong the principal component of the training distribution. As squeezing\nenhances the signal-to-noise ratio in physics, we hypothesize that scaling\nnoise in a data-dependent manner can better assist diffusion models in learning\nimportant data features. We study two configurations: (i) a Heisenberg\ndiffusion model that compensates the scaling on the principal axis with inverse\nscaling on orthogonal directions and (ii) a standard SDM variant that scales\nonly the principal axis. Counterintuitively, on CIFAR-10/100 and CelebA-64,\nmild antisqueezing - i.e. increasing variance on the principal axis -\nconsistently improves FID by up to 15% and shifts the precision-recall frontier\ntoward higher recall. Our results demonstrate that simple, data-aware noise\nshaping can deliver robust generative gains without architectural changes.", "published": "2025-08-20T17:37:53+00:00", "updated": "2025-08-20T17:37:53+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14871v1"}
{"id": "http://arxiv.org/abs/2508.14869v1", "title": "The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models", "authors": ["Hend Al-Khalifa", "Raneem Almansour", "Layan Abdulrahman Alhuasini", "Alanood Alsaleh", "Mohamad-Hani Temsah", "Mohamad-Hani_Temsah", "Ashwag Rafea S Alruwaili"], "summary": "Prompt engineering has rapidly emerged as a critical skill for effective\ninteraction with large language models (LLMs). However, the cognitive and\nneural underpinnings of this expertise remain largely unexplored. This paper\npresents findings from a cross-sectional pilot fMRI study investigating\ndifferences in brain functional connectivity and network activity between\nexperts and intermediate prompt engineers. Our results reveal distinct neural\nsignatures associated with higher prompt engineering literacy, including\nincreased functional connectivity in brain regions such as the left middle\ntemporal gyrus and the left frontal pole, as well as altered power-frequency\ndynamics in key cognitive networks. These findings offer initial insights into\nthe neurobiological basis of prompt engineering proficiency. We discuss the\nimplications of these neurocognitive markers in Natural Language Processing\n(NLP). Understanding the neural basis of human expertise in interacting with\nLLMs can inform the design of more intuitive human-AI interfaces, contribute to\ncognitive models of LLM interaction, and potentially guide the development of\nAI systems that better align with human cognitive workflows. This\ninterdisciplinary approach aims to bridge the gap between human cognition and\nmachine intelligence, fostering a deeper understanding of how humans learn and\nadapt to complex AI systems.", "published": "2025-08-20T17:31:53+00:00", "updated": "2025-08-20T17:31:53+00:00", "primary_category": "q-bio.NC", "categories": ["q-bio.NC", "cs.CL"], "pdf_url": "http://arxiv.org/pdf/2508.14869v1"}
{"id": "http://arxiv.org/abs/2508.14859v1", "title": "Graph Structure Learning with Temporal Graph Information Bottleneck for Inductive Representation Learning", "authors": ["Jiafeng Xiong", "Rizos Sakellariou"], "summary": "Temporal graph learning is crucial for dynamic networks where nodes and edges\nevolve over time and new nodes continuously join the system. Inductive\nrepresentation learning in such settings faces two major challenges:\neffectively representing unseen nodes and mitigating noisy or redundant graph\ninformation. We propose GTGIB, a versatile framework that integrates Graph\nStructure Learning (GSL) with Temporal Graph Information Bottleneck (TGIB). We\ndesign a novel two-step GSL-based structural enhancer to enrich and optimize\nnode neighborhoods and demonstrate its effectiveness and efficiency through\ntheoretical proofs and experiments. The TGIB refines the optimized graph by\nextending the information bottleneck principle to temporal graphs, regularizing\nboth edges and features based on our derived tractable TGIB objective function\nvia variational approximation, enabling stable and efficient optimization.\nGTGIB-based models are evaluated to predict links on four real-world datasets;\nthey outperform existing methods in all datasets under the inductive setting,\nwith significant and consistent improvement in the transductive setting.", "published": "2025-08-20T17:13:19+00:00", "updated": "2025-08-20T17:13:19+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14859v1"}
{"id": "http://arxiv.org/abs/2508.14858v1", "title": "Data Fusion for High-Resolution Estimation", "authors": ["Amy Guan", "Marissa Reitsma", "Roshni Sahoo", "Joshua Salomon", "Stefan Wager"], "summary": "High-resolution estimates of population health indicators are critical for\nprecision public health. We propose a method for high-resolution estimation\nthat fuses distinct data sources: an unbiased, low-resolution data source (e.g.\naggregated administrative data) and a potentially biased, high-resolution data\nsource (e.g. individual-level online survey responses). We assume that the\npotentially biased, high-resolution data source is generated from the\npopulation under a model of sampling bias where observables can have arbitrary\nimpact on the probability of response but the difference in the log\nprobabilities of response between units with the same observables is linear in\nthe difference between sufficient statistics of their observables and outcomes.\nOur data fusion method learns a distribution that is closest (in the sense of\nKL divergence) to the online survey distribution and consistent with the\naggregated administrative data and our model of sampling bias. This method\noutperforms baselines that rely on either data source alone on a testbed that\nincludes repeated measurements of three indicators measured by both the\n(online) Household Pulse Survey and ground-truth data sources at two geographic\nresolutions over the same time period.", "published": "2025-08-20T17:12:26+00:00", "updated": "2025-08-20T17:12:26+00:00", "primary_category": "stat.ME", "categories": ["stat.ME", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2508.14858v1"}
{"id": "http://arxiv.org/abs/2508.14856v1", "title": "EventSSEG: Event-driven Self-Supervised Segmentation with Probabilistic Attention", "authors": ["Lakshmi Annamalai", "Chetan Singh Thakur"], "summary": "Road segmentation is pivotal for autonomous vehicles, yet achieving low\nlatency and low compute solutions using frame based cameras remains a\nchallenge. Event cameras offer a promising alternative. To leverage their low\npower sensing, we introduce EventSSEG, a method for road segmentation that uses\nevent only computing and a probabilistic attention mechanism. Event only\ncomputing poses a challenge in transferring pretrained weights from the\nconventional camera domain, requiring abundant labeled data, which is scarce.\nTo overcome this, EventSSEG employs event-based self supervised learning,\neliminating the need for extensive labeled data. Experiments on DSEC-Semantic\nand DDD17 show that EventSSEG achieves state of the art performance with\nminimal labeled events. This approach maximizes event cameras capabilities and\naddresses the lack of labeled events.", "published": "2025-08-20T17:08:59+00:00", "updated": "2025-08-20T17:08:59+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14856v1"}
{"id": "http://arxiv.org/abs/2508.14853v1", "title": "Universal and Transferable Adversarial Attack on Large Language Models Using Exponentiated Gradient Descent", "authors": ["Sajib Biswas", "Mao Nishino", "Samuel Jacob Chacko", "Xiuwen Liu"], "summary": "As large language models (LLMs) are increasingly deployed in critical\napplications, ensuring their robustness and safety alignment remains a major\nchallenge. Despite the overall success of alignment techniques such as\nreinforcement learning from human feedback (RLHF) on typical prompts, LLMs\nremain vulnerable to jailbreak attacks enabled by crafted adversarial triggers\nappended to user prompts. Most existing jailbreak methods either rely on\ninefficient searches over discrete token spaces or direct optimization of\ncontinuous embeddings. While continuous embeddings can be given directly to\nselected open-source models as input, doing so is not feasible for proprietary\nmodels. On the other hand, projecting these embeddings back into valid discrete\ntokens introduces additional complexity and often reduces attack effectiveness.\nWe propose an intrinsic optimization method which directly optimizes relaxed\none-hot encodings of the adversarial suffix tokens using exponentiated gradient\ndescent coupled with Bregman projection, ensuring that the optimized one-hot\nencoding of each token always remains within the probability simplex. We\nprovide theoretical proof of convergence for our proposed method and implement\nan efficient algorithm that effectively jailbreaks several widely used LLMs.\nOur method achieves higher success rates and faster convergence compared to\nthree state-of-the-art baselines, evaluated on five open-source LLMs and four\nadversarial behavior datasets curated for evaluating jailbreak methods. In\naddition to individual prompt attacks, we also generate universal adversarial\nsuffixes effective across multiple prompts and demonstrate transferability of\noptimized suffixes to different LLMs.", "published": "2025-08-20T17:03:32+00:00", "updated": "2025-08-20T17:03:32+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14853v1"}
{"id": "http://arxiv.org/abs/2508.14849v1", "title": "Physics-Informed ML Exploration of Structure-Transport Relationships in Hard Carbon", "authors": ["Nikhil Rampal", "Stephen E. Weitzner", "Fredrick Omenya", "Marissa Wood", "David M. Reed", "Xiaolin Li", "Jonathan R. I. Lee", "Liwen F. Wan"], "summary": "Sodium-ion batteries are a cost-effective and sustainable alternative to\nlithium-ion systems for large-scale energy storage. Hard carbon (HC) anodes,\ncomposed of disordered graphitic and amorphous domains, offer high capacity but\nexhibit complex, poorly understood ion transport behavior. In particular, the\nrelationship between local microstructure and sodium mobility remains\nunresolved, hindering rational performance optimization. Here, we introduce a\ndata-driven framework that combines machine-learned interatomic potentials with\nmolecular dynamics simulations to systematically investigate sodium diffusion\nacross a broad range of carbon densities and sodium loadings. By computing\nper-ion structural descriptors, we identify the microscopic factors that govern\nion transport. Unsupervised learning uncovers distinct diffusion modes,\nincluding hopping, clustering, and void trapping, while supervised analysis\nhighlights tortuosity and NaNa coordination as primary determinants of\nmobility. Correlation mapping further connects these transport regimes to\nprocessing variables such as bulk density and sodium content. This\nphysics-informed approach establishes quantitative structure-transport\nrelationships that capture the heterogeneity of disordered carbon. Our findings\ndeliver mechanistic insights into sodium-ion dynamics and provide actionable\ndesign principles for engineering high-performance HC anodes in next-generation\nbattery systems.", "published": "2025-08-20T17:01:05+00:00", "updated": "2025-08-20T17:01:05+00:00", "primary_category": "cond-mat.mtrl-sci", "categories": ["cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/2508.14849v1"}
{"id": "http://arxiv.org/abs/2508.14844v1", "title": "Multimodal Quantum Vision Transformer for Enzyme Commission Classification from Biochemical Representations", "authors": ["Murat Isik", "Mandeep Kaur Saggi", "Humaira Gowher", "Sabre Kais"], "summary": "Accurately predicting enzyme functionality remains one of the major\nchallenges in computational biology, particularly for enzymes with limited\nstructural annotations or sequence homology. We present a novel multimodal\nQuantum Machine Learning (QML) framework that enhances Enzyme Commission (EC)\nclassification by integrating four complementary biochemical modalities:\nprotein sequence embeddings, quantum-derived electronic descriptors, molecular\ngraph structures, and 2D molecular image representations. Quantum Vision\nTransformer (QVT) backbone equipped with modality-specific encoders and a\nunified cross-attention fusion module. By integrating graph features and\nspatial patterns, our method captures key stereoelectronic interactions behind\nenzyme function. Experimental results demonstrate that our multimodal QVT model\nachieves a top-1 accuracy of 85.1%, outperforming sequence-only baselines by a\nsubstantial margin and achieving better performance results compared to other\nQML models.", "published": "2025-08-20T16:56:41+00:00", "updated": "2025-08-20T16:56:41+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14844v1"}
{"id": "http://arxiv.org/abs/2508.14833v1", "title": "An Investigation Into Secondary School Students' Debugging Behaviour in Python", "authors": ["Laurie Gale", "Sue Sentance"], "summary": "Background and context: Debugging is a common and often frustrating challenge\nfor beginner programmers. Understanding students' debugging processes can help\nus identify the difficulties and misunderstandings they possess. However, we\ncurrently have limited knowledge of how secondary students debug in a\ntext-based language, a medium through which millions of students will learn to\nprogram in the future. Objectives: In this paper, we investigate the debugging\nbehaviour of K-12 students learning a text-based programming language, as part\nof an effort to shape how to effectively teach debugging to these students.\nMethod: We collected log data from 73 students attempting a set of debugging\nexercises using an online code editor. We inductively analysed these logs using\nqualitative content analysis, generating a categorisation of the debugging\nbehaviours observed. Findings: A range of behaviours were exhibited by\nstudents, skewed towards being ineffective. Most students were able to\npartially locate errors but often struggled to resolve them, sometimes\nintroducing additional errors in the process. We argue that students struggling\nto debug possess fragile knowledge, a lens through which we view the results.\nImplications: This paper highlights some of the difficulties K-12 learners have\nwhen debugging in a text-based programming language. We argue, like much\nrelated work, that effective debugging strategies should be explicitly taught,\nwhile ineffective strategies should be discouraged.", "published": "2025-08-20T16:34:23+00:00", "updated": "2025-08-20T16:34:23+00:00", "primary_category": "cs.CY", "categories": ["cs.CY"], "pdf_url": "http://arxiv.org/pdf/2508.14833v1"}
{"id": "http://arxiv.org/abs/2508.14832v1", "title": "On Defining Neural Averaging", "authors": ["Su Hyeong Lee", "Richard Ngo"], "summary": "What does it even mean to average neural networks? We investigate the problem\nof synthesizing a single neural network from a collection of pretrained models,\neach trained on disjoint data shards, using only their final weights and no\naccess to training data. In forming a definition of neural averaging, we take\ninsight from model soup, which appears to aggregate multiple models into a\nsingular model while enhancing generalization performance. In this work, we\nreinterpret model souping as a special case of a broader framework: Amortized\nModel Ensembling (AME) for neural averaging, a data-free meta-optimization\napproach that treats model differences as pseudogradients to guide neural\nweight updates. We show that this perspective not only recovers model soup but\nenables more expressive and adaptive ensembling strategies. Empirically, AME\nproduces averaged neural solutions that outperform both individual experts and\nmodel soup baselines, especially in out-of-distribution settings. Our results\nsuggest a principled and generalizable notion of data-free model weight\naggregation and defines, in one sense, how to perform neural averaging.", "published": "2025-08-20T16:28:08+00:00", "updated": "2025-08-20T16:28:08+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14832v1"}
{"id": "http://arxiv.org/abs/2508.14831v1", "title": "TIME$[t] \\subseteq {\\rm SPACE}[O(\\sqrt{t})]$ via Tree Height Compression", "authors": ["Logan Nye"], "summary": "We prove a square-root space simulation for deterministic multitape Turing\nmachines, showing ${\\rm TIME}[[t] \\subseteq {\\rm SPACE}[O(\\sqrt{t})]$. The key\nstep is a Height Compression Theorem that uniformly (and in logspace) reshapes\nthe canonical left-deep succinct computation tree for a block-respecting run\ninto a binary tree whose evaluation-stack depth along any DFS path is $O(\\log\nT)$ for $T = \\lceil t/b \\rceil$, while preserving $O(b)$ work at leaves, $O(1)$\nat internal nodes, and edges that are logspace-checkable; semantic correctness\nacross merges is witnessed by an exact $O(b)$ window replay at the unique\ninterface. The proof uses midpoint (balanced) recursion, a per-path potential\nthat bounds simultaneously active interfaces by $O(\\log T)$, and an\nindegree-capping replacement of multiway merges by balanced binary combiners.\nAlgorithmically, an Algebraic Replay Engine with constant-degree maps over a\nconstant-size field, together with pointerless DFS and index-free streaming,\nensures constant-size per-level tokens and eliminates wide counters, yielding\nthe additive tradeoff $S(b)=O(b + \\log(t/b))$ for block sizes $b \\ge b_0$ with\n$b_0 = \\Theta(\\log t)$, which at the canonical choice $b = \\Theta(\\sqrt{t})$\ngives $O(\\sqrt{t})$ space; the $b_0$ threshold rules out degenerate blocks\nwhere addressing scratch would dominate the window footprint. The construction\nis uniform, relativizes, and is robust to standard model choices. Consequences\ninclude branching-program upper bounds $2^{O(\\sqrt{s})}$ for size-$s$\nbounded-fan-in circuits, tightened quadratic-time lower bounds for\nSPACE$[n]$-complete problems via the standard hierarchy argument, and\n$O(\\sqrt{t})$-space certifying interpreters; under explicit locality\nassumptions, the framework extends to geometric $d$-dimensional models.", "published": "2025-08-20T16:27:53+00:00", "updated": "2025-08-20T16:27:53+00:00", "primary_category": "cs.CC", "categories": ["cs.CC", "cs.AI", "cs.DS"], "pdf_url": "http://arxiv.org/pdf/2508.14831v1"}
{"id": "http://arxiv.org/abs/2508.14828v1", "title": "Long Chain-of-Thought Reasoning Across Languages", "authors": ["Josh Barua", "Seun Eisape", "Kayo Yin", "Alane Suhr"], "summary": "Scaling inference through long chains-of-thought (CoTs) has unlocked\nimpressive reasoning capabilities in large language models (LLMs), yet the\nreasoning process remains almost exclusively English-centric. We construct\ntranslated versions of two popular English reasoning datasets, fine-tune Qwen\n2.5 (7B) and Qwen 3 (8B) models, and present a systematic study of long CoT\ngeneration across French, Japanese, Latvian, and Swahili. Our experiments\nreveal three key findings. First, the efficacy of using English as a pivot\nlanguage varies by language: it provides no benefit for French, improves\nperformance when used as the reasoning language for Japanese and Latvian, and\nproves insufficient for Swahili where both task comprehension and reasoning\nremain poor. Second, extensive multilingual pretraining in Qwen 3 narrows but\ndoes not eliminate the cross-lingual performance gap. A lightweight fine-tune\nusing only 1k traces still improves performance by over 30\\% in Swahili. Third,\ndata quality versus scale trade-offs are language dependent: small, carefully\ncurated datasets suffice for English and French, whereas larger but noisier\ncorpora prove more effective for Swahili and Latvian. Together, these results\nclarify when and why long CoTs transfer across languages and provide translated\ndatasets to foster equitable multilingual reasoning research.", "published": "2025-08-20T16:22:51+00:00", "updated": "2025-08-20T16:22:51+00:00", "primary_category": "cs.CL", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14828v1"}
{"id": "http://arxiv.org/abs/2508.14825v1", "title": "From Passive Tool to Socio-cognitive Teammate: A Conceptual Framework for Agentic AI in Human-AI Collaborative Learning", "authors": ["Lixiang Yan"], "summary": "The role of Artificial Intelligence (AI) in education is undergoing a rapid\ntransformation, moving beyond its historical function as an instructional tool\ntowards a new potential as an active participant in the learning process. This\nshift is driven by the emergence of agentic AI, autonomous systems capable of\nproactive, goal-directed action. However, the field lacks a robust conceptual\nframework to understand, design, and evaluate this new paradigm of human-AI\ninteraction in learning. This paper addresses this gap by proposing a novel\nconceptual framework (the APCP framework) that charts the transition from AI as\na tool to AI as a collaborative partner. We present a four-level model of\nescalating AI agency within human-AI collaborative learning: (1) the AI as an\nAdaptive Instrument, (2) the AI as a Proactive Assistant, (3) the AI as a\nCo-Learner, and (4) the AI as a Peer Collaborator. Grounded in sociocultural\ntheories of learning and Computer-Supported Collaborative Learning (CSCL), this\nframework provides a structured vocabulary for analysing the shifting roles and\nresponsibilities between human and AI agents. The paper further engages in a\ncritical discussion of the philosophical underpinnings of collaboration,\nexamining whether an AI, lacking genuine consciousness or shared\nintentionality, can be considered a true collaborator. We conclude that while\nAI may not achieve authentic phenomenological partnership, it can be designed\nas a highly effective functional collaborator. This distinction has significant\nimplications for pedagogy, instructional design, and the future research agenda\nfor AI in education, urging a shift in focus towards creating learning\nenvironments that harness the complementary strengths of both human and AI.", "published": "2025-08-20T16:17:32+00:00", "updated": "2025-08-20T16:17:32+00:00", "primary_category": "cs.HC", "categories": ["cs.HC", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14825v1"}
{"id": "http://arxiv.org/abs/2508.14821v1", "title": "The C-index Multiverse", "authors": ["Bego√±a B. Sierra", "Colin McLean", "Peter S. Hall", "Catalina A. Vallejos"], "summary": "Quantifying out-of-sample discrimination performance for time-to-event\noutcomes is a fundamental step for model evaluation and selection in the\ncontext of predictive modelling. The concordance index, or C-index, is a widely\nused metric for this purpose, particularly with the growing development of\nmachine learning methods. Beyond differences between proposed C-index\nestimators (e.g. Harrell's, Uno's and Antolini's), we demonstrate the existence\nof a C-index multiverse among available R and python software, where seemingly\nequal implementations can yield different results. This can undermine\nreproducibility and complicate fair comparisons across models and studies. Key\nvariation sources include tie handling and adjustment to censoring.\nAdditionally, the absence of a standardised approach to summarise risk from\nsurvival distributions, result in another source of variation dependent on\ninput types. We demonstrate the consequences of the C-index multiverse when\nquantifying predictive performance for several survival models (from Cox\nproportional hazards to recent deep learning approaches) on publicly available\nbreast cancer data, and semi-synthetic examples. Our work emphasises the need\nfor better reporting to improve transparency and reproducibility. This article\naims to be a useful guideline, helping analysts when navigating the multiverse,\nproviding unified documentation and highlighting potential pitfalls of existing\nsoftware. All code is publicly available at:\nwww.github.com/BBolosSierra/CindexMultiverse.", "published": "2025-08-20T16:11:10+00:00", "updated": "2025-08-20T16:11:10+00:00", "primary_category": "stat.ML", "categories": ["stat.ML", "cs.LG", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/2508.14821v1"}
{"id": "http://arxiv.org/abs/2508.14820v1", "title": "The Rectilinear Marco Polo Problem", "authors": ["Ofek Gila", "Michael T. Goodrich", "Zahra Hadizadeh", "Daniel S. Hirschberg", "Shayan Taherijam"], "summary": "We study the rectilinear Marco Polo problem, which generalizes the Euclidean\nversion of the Marco Polo problem for performing geometric localization to\nrectilinear search environments, such as in geometries motivated from urban\nsettings, and to higher dimensions. In the rectilinear Marco Polo problem,\nthere is at least one point of interest (POI) within distance $n$, in either\nthe $L_1$ or $L_\\infty$ metric, from the origin. Motivated from a\nsearch-and-rescue application, our goal is to move a search point, $\\Delta$,\nfrom the origin to a location within distance $1$ of a POI. We periodically\nissue probes from $\\Delta$ out a given distance (in either the $L_1$ or\n$L_\\infty$ metric) and if a POI is within the specified distance of $\\Delta$,\nthen we learn this (but no other location information). Optimization goals are\nto minimize the number of probes and the distance traveled by $\\Delta$. We\ndescribe a number of efficient search strategies for rectilinear Marco Polo\nproblems and we analyze each one in terms of the size, $n$, of the search\ndomain, as defined by the maximum distance to a POI.", "published": "2025-08-20T16:11:03+00:00", "updated": "2025-08-20T16:11:03+00:00", "primary_category": "cs.CG", "categories": ["cs.CG", "I.3.5; F.2.2; I.2.8"], "pdf_url": "http://arxiv.org/pdf/2508.14820v1"}
{"id": "http://arxiv.org/abs/2508.14818v1", "title": "Successive Halving with Learning Curve Prediction via Latent Kronecker Gaussian Processes", "authors": ["Jihao Andreas Lin", "Nicolas Mayoraz", "Steffen Rendle", "Dima Kuzmin", "Emil Praun", "Berivan Isik"], "summary": "Successive Halving is a popular algorithm for hyperparameter optimization\nwhich allocates exponentially more resources to promising candidates. However,\nthe algorithm typically relies on intermediate performance values to make\nresource allocation decisions, which can cause it to prematurely prune slow\nstarters that would eventually become the best candidate. We investigate\nwhether guiding Successive Halving with learning curve predictions based on\nLatent Kronecker Gaussian Processes can overcome this limitation. In a\nlarge-scale empirical study involving different neural network architectures\nand a click prediction dataset, we compare this predictive approach to the\nstandard approach based on current performance values. Our experiments show\nthat, although the predictive approach achieves competitive performance, it is\nnot Pareto optimal compared to investing more resources into the standard\napproach, because it requires fully observed learning curves as training data.\nHowever, this downside could be mitigated by leveraging existing learning curve\ndata.", "published": "2025-08-20T16:10:23+00:00", "updated": "2025-08-20T16:10:23+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14818v1"}
{"id": "http://arxiv.org/abs/2508.14812v1", "title": "Repeating Words for Video-Language Retrieval with Coarse-to-Fine Objectives", "authors": ["Haoyu Zhao", "Jiaxi Gu", "Shicong Wang", "Xing Zhang", "Hang Xu", "Zuxuan Wu", "Yu-Gang Jiang"], "summary": "The explosive growth of video streaming presents challenges in achieving high\naccuracy and low training costs for video-language retrieval. However, existing\nmethods rely on large-scale pre-training to improve video retrieval\nperformance, resulting in significant computational demands. Additionally, the\nfine-grained information in videos and texts remains underexplored. To\nalleviate these problems, we propose a novel framework to learn fine-grained\nfeatures for better alignment and introduce an inference pipeline to improve\nperformance without additional training. Specifically, we employ coarse-to-fine\nobjectives to understand the semantic information of video-text pairs,\nincluding contrastive and matching learning. The fine-grained data used for\ntraining is obtained through the Granularity-Aware Representation module, which\nis designed based on similarity analysis between video frames and words in\ncaptions. Furthermore, we observe that the repetition of keywords in the\noriginal captions, referred to as \"Repetition\", can enhance retrieval\nperformance and improve alignment between video and text. Based on this\ninsight, we propose a novel and effective inference pipeline that incorporates\na voting mechanism and a new Matching Entropy metric to achieve better\nretrieval performance without requiring additional pre-training. Experimental\nresults on four benchmarks demonstrate that the proposed method outperforms\nprevious approaches. Additionally, our inference pipeline achieves significant\nperformance improvements, with a 2.1% increase in Recall@1 on the MSR-VTT\ndataset and a 1.6% increase on the DiDeMo dataset.", "published": "2025-08-20T16:03:56+00:00", "updated": "2025-08-20T16:03:56+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14812v1"}
{"id": "http://arxiv.org/abs/2508.14809v1", "title": "DINOv3 with Test-Time Training for Medical Image Registration", "authors": ["Shansong Wang", "Mojtaba Safari", "Mingzhe Hu", "Qiang Li", "Chih-Wei Chang", "Richard LJ Qiu", "Xiaofeng Yang"], "summary": "Prior medical image registration approaches, particularly learning-based\nmethods, often require large amounts of training data, which constrains\nclinical adoption. To overcome this limitation, we propose a training-free\npipeline that relies on a frozen DINOv3 encoder and test-time optimization of\nthe deformation field in feature space. Across two representative benchmarks,\nthe method is accurate and yields regular deformations. On Abdomen MR-CT, it\nattained the best mean Dice score (DSC) of 0.790 together with the lowest 95th\npercentile Hausdorff Distance (HD95) of 4.9+-5.0 and the lowest standard\ndeviation of Log-Jacobian (SDLogJ) of 0.08+-0.02. On ACDC cardiac MRI, it\nimproves mean DSC to 0.769 and reduces SDLogJ to 0.11 and HD95 to 4.8, a marked\ngain over the initial alignment. The results indicate that operating in a\ncompact foundation feature space at test time offers a practical and general\nsolution for clinical registration without additional training.", "published": "2025-08-20T15:58:19+00:00", "updated": "2025-08-20T15:58:19+00:00", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14809v1"}
{"id": "http://arxiv.org/abs/2508.14808v1", "title": "Enhancing Contrastive Link Prediction With Edge Balancing Augmentation", "authors": ["Chen-Hao Chang", "Hui-Ju Hung", "Chia-Hsun Lu", "Chih-Ya Shen"], "summary": "Link prediction is one of the most fundamental tasks in graph mining, which\nmotivates the recent studies of leveraging contrastive learning to enhance the\nperformance. However, we observe two major weaknesses of these studies: i) the\nlack of theoretical analysis for contrastive learning on link prediction, and\nii) inadequate consideration of node degrees in contrastive learning. To\naddress the above weaknesses, we provide the first formal theoretical analysis\nfor contrastive learning on link prediction, where our analysis results can\ngeneralize to the autoencoder-based link prediction models with contrastive\nlearning. Motivated by our analysis results, we propose a new graph\naugmentation approach, Edge Balancing Augmentation (EBA), which adjusts the\nnode degrees in the graph as the augmentation. We then propose a new approach,\nnamed Contrastive Link Prediction with Edge Balancing Augmentation (CoEBA),\nthat integrates the proposed EBA and the proposed new contrastive losses to\nimprove the model performance. We conduct experiments on 8 benchmark datasets.\nThe results demonstrate that our proposed CoEBA significantly outperforms the\nother state-of-the-art link prediction models.", "published": "2025-08-20T15:58:01+00:00", "updated": "2025-08-20T15:58:01+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14808v1"}
{"id": "http://arxiv.org/abs/2508.14807v1", "title": "Source-Guided Flow Matching", "authors": ["Zifan Wang", "Alice Harting", "Matthieu Barreau", "Michael M. Zavlanos", "Karl H. Johansson"], "summary": "Guidance of generative models is typically achieved by modifying the\nprobability flow vector field through the addition of a guidance field. In this\npaper, we instead propose the Source-Guided Flow Matching (SGFM) framework,\nwhich modifies the source distribution directly while keeping the pre-trained\nvector field intact. This reduces the guidance problem to a well-defined\nproblem of sampling from the source distribution. We theoretically show that\nSGFM recovers the desired target distribution exactly. Furthermore, we provide\nbounds on the Wasserstein error for the generated distribution when using an\napproximate sampler of the source distribution and an approximate vector field.\nThe key benefit of our approach is that it allows the user to flexibly choose\nthe sampling method depending on their specific problem. To illustrate this, we\nsystematically compare different sampling methods and discuss conditions for\nasymptotically exact guidance. Moreover, our framework integrates well with\noptimal flow matching models since the straight transport map generated by the\nvector field is preserved. Experimental results on synthetic 2D benchmarks,\nimage datasets, and physics-informed generative tasks demonstrate the\neffectiveness and flexibility of the proposed framework.", "published": "2025-08-20T15:56:25+00:00", "updated": "2025-08-20T15:56:25+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14807v1"}
{"id": "http://arxiv.org/abs/2508.14804v1", "title": "Learning from user's behaviour of some well-known congested traffic networks", "authors": ["Isolda Cardoso", "Lucas Venturato", "Jorgelina Walpen"], "summary": "We consider the problem of predicting users' behavior of a congested traffic\nnetwork under an equilibrium condition, the traffic assignment problem. We\npropose a two-stage machine learning approach which couples a neural network\nwith a fixed point algorithm, and we evaluate its performance along several\nclassical congested traffic networks.", "published": "2025-08-20T15:53:13+00:00", "updated": "2025-08-20T15:53:13+00:00", "primary_category": "math.OC", "categories": ["math.OC", "cs.LG", "90B20, 68T20, 90C33"], "pdf_url": "http://arxiv.org/pdf/2508.14804v1"}
{"id": "http://arxiv.org/abs/2508.14801v1", "title": "A Guide for Manual Annotation of Scientific Imagery: How to Prepare for Large Projects", "authors": ["Azim Ahmadzadeh", "Rohan Adhyapak", "Armin Iraji", "Kartik Chaurasiya", "V Aparna", "Petrus C. Martens"], "summary": "Despite the high demand for manually annotated image data, managing complex\nand costly annotation projects remains under-discussed. This is partly due to\nthe fact that leading such projects requires dealing with a set of diverse and\ninterconnected challenges which often fall outside the expertise of specific\ndomain experts, leaving practical guidelines scarce. These challenges range\nwidely from data collection to resource allocation and recruitment, from\nmitigation of biases to effective training of the annotators. This paper\nprovides a domain-agnostic preparation guide for annotation projects, with a\nfocus on scientific imagery. Drawing from the authors' extensive experience in\nmanaging a large manual annotation project, it addresses fundamental concepts\nincluding success measures, annotation subjects, project goals, data\navailability, and essential team roles. Additionally, it discusses various\nhuman biases and recommends tools and technologies to improve annotation\nquality and efficiency. The goal is to encourage further research and\nframeworks for creating a comprehensive knowledge base to reduce the costs of\nmanual annotation projects across various fields.", "published": "2025-08-20T15:52:10+00:00", "updated": "2025-08-20T15:52:10+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14801v1"}
{"id": "http://arxiv.org/abs/2508.14789v1", "title": "Quantifying How Much Has Been Learned from a Research Study", "authors": ["Jonas M. Mikhaeil", "Donald P. Green"], "summary": "How much does a research study contribute to a scientific literature? We\npropose a learning metric to quantify how much a research community learns from\na given study. To do so, we adopt a Bayesian perspective and assess changes in\nthe community's beliefs once updated with a new study's evidence. We recommend\nthe Wasserstein-2 distance as a way to describe how the research community's\nprior beliefs change to incorporate a study's findings. We illustrate this\napproach through stylized examples and empirical applications, showing how it\ndiffers from more traditional evaluative standards, such as statistical\nsignificance. We then extend the framework to the prospective setting, offering\na way for decision-makers to evaluate the expected amount of learning from a\nproposed study. While assessments about what has or could be learned from a\nresearch program are often expressed informally, our learning metric provides a\nprincipled tool for judging scientific contributions. By formalizing these\njudgments, our measure has the potential to allow for more transparent\nassessments of past and prospective research contributions.", "published": "2025-08-20T15:35:04+00:00", "updated": "2025-08-20T15:35:04+00:00", "primary_category": "stat.ME", "categories": ["stat.ME", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/2508.14789v1"}
{"id": "http://arxiv.org/abs/2508.14786v1", "title": "Benefiting from Negative yet Informative Feedback by Contrasting Opposing Sequential Patterns", "authors": ["Veronika Ivanova", "Evgeny Frolov", "Alexey Vasilev"], "summary": "We consider the task of learning from both positive and negative feedback in\na sequential recommendation scenario, as both types of feedback are often\npresent in user interactions. Meanwhile, conventional sequential learning\nmodels usually focus on considering and predicting positive interactions,\nignoring that reducing items with negative feedback in recommendations improves\nuser satisfaction with the service. Moreover, the negative feedback can\npotentially provide a useful signal for more accurate identification of true\nuser interests. In this work, we propose to train two transformer encoders on\nseparate positive and negative interaction sequences. We incorporate both types\nof feedback into the training objective of the sequential recommender using a\ncomposite loss function that includes positive and negative cross-entropy as\nwell as a cleverly crafted contrastive term, that helps better modeling\nopposing patterns. We demonstrate the effectiveness of this approach in terms\nof increasing true-positive metrics compared to state-of-the-art sequential\nrecommendation methods while reducing the number of wrongly promoted negative\nitems.", "published": "2025-08-20T15:32:16+00:00", "updated": "2025-08-20T15:32:16+00:00", "primary_category": "cs.IR", "categories": ["cs.IR"], "pdf_url": "http://arxiv.org/pdf/2508.14786v1"}
{"id": "http://arxiv.org/abs/2508.14784v1", "title": "Graph Learning for Foreign Exchange Rate Prediction and Statistical Arbitrage", "authors": ["Yoonsik Hong", "Diego Klabjan"], "summary": "We propose a two-step graph learning approach for foreign exchange\nstatistical arbitrages (FXSAs), addressing two key gaps in prior studies: the\nabsence of graph-learning methods for foreign exchange rate prediction (FXRP)\nthat leverage multi-currency and currency-interest rate relationships, and the\ndisregard of the time lag between price observation and trade execution. In the\nfirst step, to capture complex multi-currency and currency-interest rate\nrelationships, we formulate FXRP as an edge-level regression problem on a\ndiscrete-time spatiotemporal graph. This graph consists of currencies as nodes\nand exchanges as edges, with interest rates and foreign exchange rates serving\nas node and edge features, respectively. We then introduce a graph-learning\nmethod that leverages the spatiotemporal graph to address the FXRP problem. In\nthe second step, we present a stochastic optimization problem to exploit FXSAs\nwhile accounting for the observation-execution time lag. To address this\nproblem, we propose a graph-learning method that enforces constraints through\nprojection and ReLU, maximizes risk-adjusted return by leveraging a graph with\nexchanges as nodes and influence relationships as edges, and utilizes the\npredictions from the FXRP method for the constraint parameters and node\nfeatures. Moreover, we prove that our FXSA method satisfies empirical arbitrage\nconstraints. The experimental results demonstrate that our FXRP method yields\nstatistically significant improvements in mean squared error, and that the FXSA\nmethod achieves a 61.89% higher information ratio and a 45.51% higher Sortino\nratio than a benchmark. Our approach provides a novel perspective on FXRP and\nFXSA within the context of graph learning.", "published": "2025-08-20T15:29:31+00:00", "updated": "2025-08-20T15:29:31+00:00", "primary_category": "q-fin.TR", "categories": ["q-fin.TR"], "pdf_url": "http://arxiv.org/pdf/2508.14784v1"}
{"id": "http://arxiv.org/abs/2508.14783v1", "title": "Synthetic Adaptive Guided Embeddings (SAGE): A Novel Knowledge Distillation Method", "authors": ["Suleyman Olcay Polat", "Poli A. Nemkova", "Mark V. Albert"], "summary": "Model distillation enables the transfer of knowledge from large-scale models\nto compact student models, facilitating deployment in resource-constrained\nenvironments. However, conventional distillation approaches often suffer from\ncomputational overhead and limited generalization. We propose a novel adaptive\ndistillation framework that dynamically augments training data in regions of\nhigh student model loss. Using UMAP-based dimensionality reduction and nearest\nneighbor sampling, our method identifies underperforming regions in the\nembedding space and generates targeted synthetic examples to guide student\nlearning. To further improve efficiency, we introduce a lightweight\nteacher-student interface that bypasses the teacher's input layer, enabling\ndirect distillation on vectorized representations. Experiments across standard\nNLP benchmarks demonstrate that our 66M-parameter student model consistently\nmatches or surpasses established baselines, achieving 91.2% on QNLI and 92.3%\non SST-2, while training with fewer epochs. These results highlight the promise\nof loss-aware data augmentation and vectorized distillation for efficient and\neffective model compression.", "published": "2025-08-20T15:29:00+00:00", "updated": "2025-08-20T15:29:00+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14783v1"}
{"id": "http://arxiv.org/abs/2508.14782v1", "title": "TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting", "authors": ["Jiaming Leng", "Yunying Bi", "Chuan Qin", "Bing Yin", "Yanyong Zhang", "Chao Wang"], "summary": "Urban transportation systems encounter diverse challenges across multiple\ntasks, such as traffic forecasting, electric vehicle (EV) charging demand\nprediction, and taxi dispatch. Existing approaches suffer from two key\nlimitations: small-scale deep learning models are task-specific and\ndata-hungry, limiting their generalizability across diverse scenarios, while\nlarge language models (LLMs), despite offering flexibility through natural\nlanguage interfaces, struggle with structured spatiotemporal data and numerical\nreasoning in transportation domains. To address these limitations, we propose\nTransLLM, a unified foundation framework that integrates spatiotemporal\nmodeling with large language models through learnable prompt composition. Our\napproach features a lightweight spatiotemporal encoder that captures complex\ndependencies via dilated temporal convolutions and dual-adjacency graph\nattention networks, seamlessly interfacing with LLMs through structured\nembeddings. A novel instance-level prompt routing mechanism, trained via\nreinforcement learning, dynamically personalizes prompts based on input\ncharacteristics, moving beyond fixed task-specific templates. The framework\noperates by encoding spatiotemporal patterns into contextual representations,\ndynamically composing personalized prompts to guide LLM reasoning, and\nprojecting the resulting representations through specialized output layers to\ngenerate task-specific predictions. Experiments across seven datasets and three\ntasks demonstrate the exceptional effectiveness of TransLLM in both supervised\nand zero-shot settings. Compared to ten baseline models, it delivers\ncompetitive performance on both regression and planning problems, showing\nstrong generalization and cross-task adaptability. Our code is available at\nhttps://github.com/BiYunying/TransLLM.", "published": "2025-08-20T15:27:49+00:00", "updated": "2025-08-20T15:27:49+00:00", "primary_category": "cs.CL", "categories": ["cs.CL", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14782v1"}
{"id": "http://arxiv.org/abs/2508.14780v1", "title": "Context Steering: A New Paradigm for Compression-based Embeddings by Synthesizing Relevant Information Features", "authors": ["Guillermo Sarasa Dur√°n", "Ana Granados Fontecha", "Francisco de Borja Rodr√≠guez Ort√≠z"], "summary": "Compression-based distances (CD) offer a flexible and domain-agnostic means\nof measuring similarity by identifying implicit information through\nredundancies between data objects. However, as similarity features are derived\nfrom the data, rather than defined as an input, it often proves difficult to\nalign with the task at hand, particularly in complex clustering or\nclassification settings. To address this issue, we introduce \"context\nsteering,\" a novel methodology that actively guides the feature-shaping\nprocess. Instead of passively accepting the emergent data structure (typically\na hierarchy derived from clustering CDs), our approach \"steers\" the process by\nsystematically analyzing how each object influences the relational context\nwithin a clustering framework. This process generates a custom-tailored\nembedding that isolates and amplifies class-distinctive information. We\nvalidate the capabilities of this strategy using Normalized Compression\nDistance (NCD) and Relative Compression Distance (NRC) with common hierarchical\nclustering, providing an effective alternative to common transductive methods.\nExperimental results across heterogeneous datasets-from text to real-world\naudio-validate the robustness and generality of context steering, marking a\nfundamental shift in their application: from merely discovering inherent data\nstructures to actively shaping a feature space tailored to a specific\nobjective.", "published": "2025-08-20T15:26:52+00:00", "updated": "2025-08-20T15:26:52+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2508.14780v1"}
{"id": "http://arxiv.org/abs/2508.14779v1", "title": "Adversarial Hospital-Invariant Feature Learning for WSI Patch Classification", "authors": ["Mengliang Zhang", "Jacob M. Luber"], "summary": "Pathology foundation models (PFMs) have demonstrated remarkable potential in\nwhole-slide image (WSI) diagnosis. However, pathology images from different\nhospitals often vary due to differences in scanning hardware and preprocessing\nstyles, which may lead PFMs to inadvertently learn hospital-specific features,\nposing risks for clinical deployment. In this work, we present the first\nsystematic study of domain bias in PFMs arising from hospital source\ncharacteristics. Specifically, we (1) construct a pipeline for quantifying\ndomain bias in PFMs, (2) evaluate and compare the performance of multiple\nmodels, and (3) propose a lightweight adversarial framework that removes latent\nhospital-specific features from frozen representations without modifying the\nencoder itself. By introducing a trainable adapter and a domain classifier\nconnected through a gradient reversal layer (GRL), our method learns\ntask-discriminative yet domain-invariant representations. Experiments on\nmulti-center histopathology datasets demonstrate that our approach\nsubstantially reduces domain predictability while maintaining or even improving\ndisease classification performance, particularly in out-of-domain (unseen\nhospital) scenarios. Further analyses, including hospital detection and feature\nspace visualization, confirm the effectiveness of our method in mitigating\nhospital bias. We will provide our code based on acceptance.", "published": "2025-08-20T15:25:16+00:00", "updated": "2025-08-20T15:25:16+00:00", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2508.14779v1"}
{"id": "http://arxiv.org/abs/2508.14778v1", "title": "Analyzing Undergraduate Problem-Solving in Physics Through Interaction With an AI Chatbot", "authors": ["Syed Furqan Abbas Hashmi", "N. Sanjay Rebello"], "summary": "Providing individualized scaffolding for physics problem solving at scale\nremains an instructional challenge. We investigate (1) students' perceptions of\na Socratic Artificial Intelligence (AI) chatbot's impact on problem-solving\nskills and confidence and (2) how the specificity of students' questions during\ntutoring relates to performance. We deployed a custom Socratic AI chatbot in a\nlarge-enrollment introductory mechanics course at a Midwestern public\nuniversity, logging full dialogue transcripts from 150 first-year STEM majors.\nPost-interaction surveys revealed median ratings of 4.0/5 for knowledge-based\nskills and 3.4/5 for overall effectiveness. Transcript analysis showed question\nspecificity rose from approximately 10-15% in the first turn to 100% by the\nfinal turn, and specificity correlated positively with self reported expected\ncourse grade (Pearson r = 0.43). These findings demonstrate that AI-driven\nSocratic dialogue not only fosters expert-like reasoning but also generates\nfine-grained analytics for physics education research, establishing a scalable\ndual-purpose tool for instruction and learning analytics.", "published": "2025-08-20T15:24:35+00:00", "updated": "2025-08-20T15:24:35+00:00", "primary_category": "physics.ed-ph", "categories": ["physics.ed-ph"], "pdf_url": "http://arxiv.org/pdf/2508.14778v1"}
{"id": "http://arxiv.org/abs/2508.14769v1", "title": "Federated Distillation on Edge Devices: Efficient Client-Side Filtering for Non-IID Data", "authors": ["Ahmed Mujtaba", "Gleb Radchenko", "Radu Prodan", "Marc Masana"], "summary": "Federated distillation has emerged as a promising collaborative machine\nlearning approach, offering enhanced privacy protection and reduced\ncommunication compared to traditional federated learning by exchanging model\noutputs (soft logits) rather than full model parameters. However, existing\nmethods employ complex selective knowledge-sharing strategies that require\nclients to identify in-distribution proxy data through computationally\nexpensive statistical density ratio estimators. Additionally, server-side\nfiltering of ambiguous knowledge introduces latency to the process. To address\nthese challenges, we propose a robust, resource-efficient EdgeFD method that\nreduces the complexity of the client-side density ratio estimation and removes\nthe need for server-side filtering. EdgeFD introduces an efficient KMeans-based\ndensity ratio estimator for effectively filtering both in-distribution and\nout-of-distribution proxy data on clients, significantly improving the quality\nof knowledge sharing. We evaluate EdgeFD across diverse practical scenarios,\nincluding strong non-IID, weak non-IID, and IID data distributions on clients,\nwithout requiring a pre-trained teacher model on the server for knowledge\ndistillation. Experimental results demonstrate that EdgeFD outperforms\nstate-of-the-art methods, consistently achieving accuracy levels close to IID\nscenarios even under heterogeneous and challenging conditions. The\nsignificantly reduced computational overhead of the KMeans-based estimator is\nsuitable for deployment on resource-constrained edge devices, thereby enhancing\nthe scalability and real-world applicability of federated distillation. The\ncode is available online for reproducibility.", "published": "2025-08-20T15:17:59+00:00", "updated": "2025-08-20T15:17:59+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.DC"], "pdf_url": "http://arxiv.org/pdf/2508.14769v1"}
{"id": "http://arxiv.org/abs/2508.14766v1", "title": "Algorithmic Collusion is Algorithm Orchestration", "authors": ["Cesare Carissimo", "Fryderyk Falniowski", "Siavash Rahimi", "Heinrich Nax"], "summary": "This paper proposes a fresh `meta-game' perspective on the problem of\nalgorithmic collusion in pricing games a la Bertrand. Economists have\ninterpreted the fact that algorithms can learn to price collusively as tacit\ncollusion. We argue instead that the co-parametrization of algorithms -- that\nwe show is necessary to obtain algorithmic collusion -- requires algorithm\ndesigner(s) to engage in explicit collusion by algorithm orchestration. To\nhighlight this, we model a meta-game of algorithm parametrization that is\nplayed by algorithm designers, and the relevant strategic analyses at that\nlevel reveal new equilibrium and collusion phenomena.", "published": "2025-08-20T15:16:16+00:00", "updated": "2025-08-20T15:16:16+00:00", "primary_category": "econ.TH", "categories": ["econ.TH", "cs.GT"], "pdf_url": "http://arxiv.org/pdf/2508.14766v1"}
{"id": "http://arxiv.org/abs/2508.14765v1", "title": "PepThink-R1: LLM for Interpretable Cyclic Peptide Optimization with CoT SFT and Reinforcement Learning", "authors": ["Ruheng Wang", "Hang Zhang", "Trieu Nguyen", "Shasha Feng", "Hao-Wei Pang", "Xiang Yu", "Li Xiao", "Peter Zhiping Zhang"], "summary": "Designing therapeutic peptides with tailored properties is hindered by the\nvastness of sequence space, limited experimental data, and poor\ninterpretability of current generative models. To address these challenges, we\nintroduce PepThink-R1, a generative framework that integrates large language\nmodels (LLMs) with chain-of-thought (CoT) supervised fine-tuning and\nreinforcement learning (RL). Unlike prior approaches, PepThink-R1 explicitly\nreasons about monomer-level modifications during sequence generation, enabling\ninterpretable design choices while optimizing for multiple pharmacological\nproperties. Guided by a tailored reward function balancing chemical validity\nand property improvements, the model autonomously explores diverse sequence\nvariants. We demonstrate that PepThink-R1 generates cyclic peptides with\nsignificantly enhanced lipophilicity, stability, and exposure, outperforming\nexisting general LLMs (e.g., GPT-5) and domain-specific baseline in both\noptimization success and interpretability. To our knowledge, this is the first\nLLM-based peptide design framework that combines explicit reasoning with\nRL-driven property control, marking a step toward reliable and transparent\npeptide optimization for therapeutic discovery.", "published": "2025-08-20T15:13:52+00:00", "updated": "2025-08-20T15:13:52+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14765v1"}
{"id": "http://arxiv.org/abs/2508.14762v1", "title": "Statistical Arbitrage in Options Markets by Graph Learning and Synthetic Long Positions", "authors": ["Yoonsik Hong", "Diego Klabjan"], "summary": "Statistical arbitrages (StatArbs) driven by machine learning has garnered\nconsiderable attention in both academia and industry. Nevertheless,\ndeep-learning (DL) approaches to directly exploit StatArbs in options markets\nremain largely unexplored. Moreover, prior graph learning (GL) -- a\nmethodological basis of this paper -- studies overlooked that features are\ntabular in many cases and that tree-based methods outperform DL on numerous\ntabular datasets. To bridge these gaps, we propose a two-stage GL approach for\ndirect identification and exploitation of StatArbs in options markets. In the\nfirst stage, we define a novel prediction target isolating pure arbitrages via\nsynthetic bonds. To predict the target, we develop RNConv, a GL architecture\nincorporating a tree structure. In the second stage, we propose SLSA -- a class\nof positions comprising pure arbitrage opportunities. It is provably of minimal\nrisk and neutral to all Black-Scholes risk factors under the arbitrage-free\nassumption. We also present the SLSA projection converting predictions into\nSLSA positions. Our experiments on KOSPI 200 index options show that RNConv\nstatistically significantly outperforms GL baselines, and that SLSA\nconsistently yields positive returns, achieving an average P&L-contract\ninformation ratio of 0.1627. Our approach offers a novel perspective on the\nprediction target and strategy for exploiting StatArbs in options markets\nthrough the lens of DL, in conjunction with a pioneering tree-based GL.", "published": "2025-08-20T15:08:26+00:00", "updated": "2025-08-20T15:08:26+00:00", "primary_category": "q-fin.PR", "categories": ["q-fin.PR"], "pdf_url": "http://arxiv.org/pdf/2508.14762v1"}
{"id": "http://arxiv.org/abs/2508.14761v1", "title": "Reinforcement learning entangling operations on spin qubits", "authors": ["Mohammad Abedi", "Markus Schmitt"], "summary": "High-fidelity control of one- and two-qubit gates past the error correction\nthreshold is an essential ingredient for scalable quantum computing. We present\na reinforcement learning (RL) approach to find entangling protocols for\nsemiconductor-based singlet-triplet qubits in a double quantum dot. Despite the\npresence of realistically modelled experimental constraints, such as various\nnoise contributions and finite rise-time effects, we demonstrate that an RL\nagent can yield performative protocols, while avoiding the model-biases of\ntraditional gradient-based methods. We optimise our RL approach for different\nregimes and tasks, including training from simulated process tomography\nreconstruction of unitary gates, and investigate the nuances of RL agent\ndesign.", "published": "2025-08-20T15:05:38+00:00", "updated": "2025-08-20T15:05:38+00:00", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2508.14761v1"}
{"id": "http://arxiv.org/abs/2508.14757v1", "title": "Distributional Adversarial Attacks and Training in Deep Hedging", "authors": ["Guangyi He", "Tobias Sutter", "Lukas Gonon"], "summary": "In this paper, we study the robustness of classical deep hedging strategies\nunder distributional shifts by leveraging the concept of adversarial attacks.\nWe first demonstrate that standard deep hedging models are highly vulnerable to\nsmall perturbations in the input distribution, resulting in significant\nperformance degradation. Motivated by this, we propose an adversarial training\nframework tailored to increase the robustness of deep hedging strategies. Our\napproach extends pointwise adversarial attacks to the distributional setting\nand introduces a computationally tractable reformulation of the adversarial\noptimization problem over a Wasserstein ball. This enables the efficient\ntraining of hedging strategies that are resilient to distributional\nperturbations. Through extensive numerical experiments, we show that\nadversarially trained deep hedging strategies consistently outperform their\nclassical counterparts in terms of out-of-sample performance and resilience to\nmodel misspecification. Our findings establish a practical and effective\nframework for robust deep hedging under realistic market uncertainties.", "published": "2025-08-20T14:59:32+00:00", "updated": "2025-08-20T14:59:32+00:00", "primary_category": "math.OC", "categories": ["math.OC", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14757v1"}
{"id": "http://arxiv.org/abs/2508.14751v1", "title": "HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents", "authors": ["Thomas Carta", "Cl√©ment Romac", "Loris Gaven", "Pierre-Yves Oudeyer", "Olivier Sigaud", "Sylvain Lamprier"], "summary": "Open-ended AI agents need to be able to learn efficiently goals of increasing\ncomplexity, abstraction and heterogeneity over their lifetime. Beyond sampling\nefficiently their own goals, autotelic agents specifically need to be able to\nkeep the growing complexity of goals under control, limiting the associated\ngrowth in sample and computational complexity. To adress this challenge, recent\napproaches have leveraged hierarchical reinforcement learning (HRL) and\nlanguage, capitalizing on its compositional and combinatorial generalization\ncapabilities to acquire temporally extended reusable behaviours. Existing\napproaches use expert defined spaces of subgoals over which they instantiate a\nhierarchy, and often assume pre-trained associated low-level policies. Such\ndesigns are inadequate in open-ended scenarios, where goal spaces naturally\ndiversify across a broad spectrum of difficulties. We introduce HERAKLES, a\nframework that enables a two-level hierarchical autotelic agent to continuously\ncompile mastered goals into the low-level policy, executed by a small, fast\nneural network, dynamically expanding the set of subgoals available to the\nhigh-level policy. We train a Large Language Model (LLM) to serve as the\nhigh-level controller, exploiting its strengths in goal decomposition and\ngeneralization to operate effectively over this evolving subgoal space. We\nevaluate HERAKLES in the open-ended Crafter environment and show that it scales\neffectively with goal complexity, improves sample efficiency through skill\ncompilation, and enables the agent to adapt robustly to novel challenges over\ntime.", "published": "2025-08-20T14:50:28+00:00", "updated": "2025-08-20T14:50:28+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14751v1"}
{"id": "http://arxiv.org/abs/2508.14748v1", "title": "Cross-Modality Controlled Molecule Generation with Diffusion Language Model", "authors": ["Yunzhe Zhang", "Yifei Wang", "Khanh Vinh Nguyen", "Pengyu Hong"], "summary": "Current SMILES-based diffusion models for molecule generation typically\nsupport only unimodal constraint. They inject conditioning signals at the start\nof the training process and require retraining a new model from scratch\nwhenever the constraint changes. However, real-world applications often involve\nmultiple constraints across different modalities, and additional constraints\nmay emerge over the course of a study. This raises a challenge: how to extend a\npre-trained diffusion model not only to support cross-modality constraints but\nalso to incorporate new ones without retraining. To tackle this problem, we\npropose the Cross-Modality Controlled Molecule Generation with Diffusion\nLanguage Model (CMCM-DLM), demonstrated by two distinct cross modalities:\nmolecular structure and chemical properties. Our approach builds upon a\npre-trained diffusion model, incorporating two trainable modules, the Structure\nControl Module (SCM) and the Property Control Module (PCM), and operates in two\ndistinct phases during the generation process. In Phase I, we employs the SCM\nto inject structural constraints during the early diffusion steps, effectively\nanchoring the molecular backbone. Phase II builds on this by further\nintroducing PCM to guide the later stages of inference to refine the generated\nmolecules, ensuring their chemical properties match the specified targets.\nExperimental results on multiple datasets demonstrate the efficiency and\nadaptability of our approach, highlighting CMCM-DLM's significant advancement\nin molecular generation for drug discovery applications.", "published": "2025-08-20T14:48:44+00:00", "updated": "2025-08-20T14:48:44+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14748v1"}
{"id": "http://arxiv.org/abs/2508.14746v1", "title": "MissionHD: Data-Driven Refinement of Reasoning Graph Structure through Hyperdimensional Causal Path Encoding and Decoding", "authors": ["Sanggeon Yun", "Raheeb Hassan", "Ryozo Masukawa", "Mohsen Imani"], "summary": "Reasoning graphs from Large Language Models (LLMs) are often misaligned with\ndownstream visual tasks such as video anomaly detection (VAD). Existing Graph\nStructure Refinement (GSR) methods are ill-suited for these novel, dataset-less\ngraphs. We introduce Data-driven GSR (D-GSR), a new paradigm that directly\noptimizes graph structure using downstream task data, and propose MissionHD, a\nhyperdimensional computing (HDC) framework to operationalize it. MissionHD uses\nan efficient encode-decode process to refine the graph, guided by the\ndownstream task signal. Experiments on challenging VAD and VAR benchmarks show\nsignificant performance improvements when using our refined graphs, validating\nour approach as an effective pre-processing step.", "published": "2025-08-20T14:43:04+00:00", "updated": "2025-08-20T14:43:04+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14746v1"}
{"id": "http://arxiv.org/abs/2508.14741v1", "title": "CaTE Data Curation for Trustworthy AI", "authors": ["Mary Versa Clemens-Sewall", "Christopher Cervantes", "Emma Rafkin", "J. Neil Otte", "Tom Magelinski", "Libby Lewis", "Michelle Liu", "Dana Udwin", "Monique Kirkman-Bey"], "summary": "This report provides practical guidance to teams designing or developing\nAI-enabled systems for how to promote trustworthiness during the data curation\nphase of development. In this report, the authors first define data, the data\ncuration phase, and trustworthiness. We then describe a series of steps that\nthe development team, especially data scientists, can take to build a\ntrustworthy AI-enabled system. We enumerate the sequence of core steps and\ntrace parallel paths where alternatives exist. The descriptions of these steps\ninclude strengths, weaknesses, preconditions, outcomes, and relevant\nopen-source software tool implementations. In total, this report is a synthesis\nof data curation tools and approaches from relevant academic literature, and\nour goal is to equip readers with a diverse yet coherent set of practices for\nimproving AI trustworthiness.", "published": "2025-08-20T14:40:21+00:00", "updated": "2025-08-20T14:40:21+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14741v1"}
{"id": "http://arxiv.org/abs/2508.14739v1", "title": "Failure Tolerant Phase-Only Indoor Positioning via Deep Learning", "authors": ["Fatih Ayten", "Mehmet C. Ilter", "Akshay Jain", "Ossi Kaltiokallio", "Jukka Talvitie", "Elena Simona Lohan", "Henk Wymeersch", "Mikko Valkama"], "summary": "High-precision localization turns into a crucial added value and asset for\nnext-generation wireless systems. Carrier phase positioning (CPP) enables\nsub-meter to centimeter-level accuracy and is gaining interest in 5G-Advanced\nstandardization. While CPP typically complements time-of-arrival (ToA)\nmeasurements, recent literature has introduced a phase-only positioning\napproach in a distributed antenna/MIMO system context with minimal bandwidth\nrequirements, using deep learning (DL) when operating under ideal hardware\nassumptions. In more practical scenarios, however, antenna failures can largely\ndegrade the performance. In this paper, we address the challenging phase-only\npositioning task, and propose a new DL-based localization approach harnessing\nthe so-called hyperbola intersection principle, clearly outperforming the\nprevious methods. Additionally, we consider and propose a processing and\nlearning mechanism that is robust to antenna element failures. Our results show\nthat the proposed DL model achieves robust and accurate positioning despite\nantenna impairments, demonstrating the viability of data-driven,\nimpairment-tolerant phase-only positioning mechanisms. Comprehensive set of\nnumerical results demonstrates large improvements in localization accuracy\nagainst the prior art methods.", "published": "2025-08-20T14:37:50+00:00", "updated": "2025-08-20T14:37:50+00:00", "primary_category": "eess.SP", "categories": ["eess.SP"], "pdf_url": "http://arxiv.org/pdf/2508.14739v1"}
{"id": "http://arxiv.org/abs/2508.14734v1", "title": "AFABench: A Generic Framework for Benchmarking Active Feature Acquisition", "authors": ["Valter Sch√ºtz", "Han Wu", "Reza Rezvan", "Linus Aronsson", "Morteza Haghir Chehreghani"], "summary": "In many real-world scenarios, acquiring all features of a data instance can\nbe expensive or impractical due to monetary cost, latency, or privacy concerns.\nActive Feature Acquisition (AFA) addresses this challenge by dynamically\nselecting a subset of informative features for each data instance, trading\npredictive performance against acquisition cost. While numerous methods have\nbeen proposed for AFA, ranging from greedy information-theoretic strategies to\nnon-myopic reinforcement learning approaches, fair and systematic evaluation of\nthese methods has been hindered by the lack of standardized benchmarks. In this\npaper, we introduce AFABench, the first benchmark framework for AFA. Our\nbenchmark includes a diverse set of synthetic and real-world datasets, supports\na wide range of acquisition policies, and provides a modular design that\nenables easy integration of new methods and tasks. We implement and evaluate\nrepresentative algorithms from all major categories, including static, greedy,\nand reinforcement learning-based approaches. To test the lookahead capabilities\nof AFA policies, we introduce a novel synthetic dataset, AFAContext, designed\nto expose the limitations of greedy selection. Our results highlight key\ntrade-offs between different AFA strategies and provide actionable insights for\nfuture research. The benchmark code is available at:\nhttps://github.com/Linusaronsson/AFA-Benchmark.", "published": "2025-08-20T14:29:16+00:00", "updated": "2025-08-20T14:29:16+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14734v1"}
{"id": "http://arxiv.org/abs/2508.14730v1", "title": "Improved Mapping Between Illuminations and Sensors for RAW Images", "authors": ["Abhijith Punnappurath", "Luxi Zhao", "Hoang Le", "Abdelrahman Abdelhamed", "SaiKiran Kumar Tedla", "Michael S. Brown"], "summary": "RAW images are unprocessed camera sensor output with sensor-specific RGB\nvalues based on the sensor's color filter spectral sensitivities. RAW images\nalso incur strong color casts due to the sensor's response to the spectral\nproperties of scene illumination. The sensor- and illumination-specific nature\nof RAW images makes it challenging to capture RAW datasets for deep learning\nmethods, as scenes need to be captured for each sensor and under a wide range\nof illumination. Methods for illumination augmentation for a given sensor and\nthe ability to map RAW images between sensors are important for reducing the\nburden of data capture. To explore this problem, we introduce the\nfirst-of-its-kind dataset comprising carefully captured scenes under a wide\nrange of illumination. Specifically, we use a customized lightbox with tunable\nillumination spectra to capture several scenes with different cameras. Our\nillumination and sensor mapping dataset has 390 illuminations, four cameras,\nand 18 scenes. Using this dataset, we introduce a lightweight neural network\napproach for illumination and sensor mapping that outperforms competing\nmethods. We demonstrate the utility of our approach on the downstream task of\ntraining a neural ISP. Link to project page:\nhttps://github.com/SamsungLabs/illum-sensor-mapping.", "published": "2025-08-20T14:23:23+00:00", "updated": "2025-08-20T14:23:23+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14730v1"}
{"id": "http://arxiv.org/abs/2508.14727v1", "title": "Assessing the Quality and Security of AI-Generated Code: A Quantitative Analysis", "authors": ["Abbas Sabra", "Olivier Schmitt", "Joseph Tyler"], "summary": "This study presents a quantitative evaluation of the code quality and\nsecurity of five prominent Large Language Models (LLMs): Claude Sonnet 4,\nClaude 3.7 Sonnet, GPT-4o, Llama 3.2 90B, and OpenCoder 8B. While prior\nresearch has assessed the functional performance of LLM-generated code, this\nresearch tested LLM output from 4,442 Java coding assignments through\ncomprehensive static analysis using SonarQube. The findings suggest that\nalthough LLMs can generate functional code, they also introduce a range of\nsoftware defects, including bugs, security vulnerabilities, and code smells.\nThese defects do not appear to be isolated; rather, they may represent shared\nweaknesses stemming from systemic limitations within current LLM code\ngeneration methods. In particular, critically severe issues, such as hard-coded\npasswords and path traversal vulnerabilities, were observed across multiple\nmodels. These results indicate that LLM-generated code requires verification in\norder to be considered production-ready. This study found no direct correlation\nbetween a model's functional performance (measured by Pass@1 rate of unit\ntests) and the overall quality and security of its generated code, measured by\nthe number of SonarQube issues in benchmark solutions that passed the\nfunctional tests. This suggests that functional benchmark performance score is\nnot a good indicator of overall code quality and security. The goal of this\nstudy is not to rank LLM performance but to highlight that all evaluated models\nappear to share certain weaknesses. Consequently, these findings support the\nview that static analysis can be a valuable instrument for detecting latent\ndefects and an important safeguard for organizations that deploy AI in software\ndevelopment.", "published": "2025-08-20T14:16:21+00:00", "updated": "2025-08-20T14:16:21+00:00", "primary_category": "cs.SE", "categories": ["cs.SE", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14727v1"}
{"id": "http://arxiv.org/abs/2508.14723v1", "title": "Transplant Then Regenerate: A New Paradigm for Text Data Augmentation", "authors": ["Guangzhan Wang", "Hongyu Zhang", "Beijun Shen", "Xiaodong Gu"], "summary": "Data augmentation is a critical technique in deep learning. Traditional\nmethods like Back-translation typically focus on lexical-level rephrasing,\nwhich primarily produces variations with the same semantics. While large\nlanguage models (LLMs) have enhanced text augmentation by their \"knowledge\nemergence\" capability, controlling the style and structure of these outputs\nremains challenging and requires meticulous prompt engineering. In this paper,\nwe propose LMTransplant, a novel text augmentation paradigm leveraging LLMs.\nThe core idea of LMTransplant is transplant-then-regenerate: incorporating seed\ntext into a context expanded by LLM, and asking the LLM to regenerate a variant\nbased on the expanded context. This strategy allows the model to create more\ndiverse and creative content-level variants by fully leveraging the knowledge\nembedded in LLMs, while preserving the core attributes of the original text. We\nevaluate LMTransplant across various text-related tasks, demonstrating its\nsuperior performance over existing text augmentation methods. Moreover,\nLMTransplant demonstrates exceptional scalability as the size of augmented data\ngrows.", "published": "2025-08-20T14:05:18+00:00", "updated": "2025-08-20T14:05:18+00:00", "primary_category": "cs.CL", "categories": ["cs.CL", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14723v1"}
{"id": "http://arxiv.org/abs/2508.14715v1", "title": "Recursive Gaussian Process Regression with Integrated Monotonicity Assumptions for Control Applications", "authors": ["Ricus Husmann", "Sven Weishaupt", "Harald Aschemann"], "summary": "In this paper, we present an extension to the recursive Gaussian Process\n(RGP) regression that enables the satisfaction of inequality constraints and is\nwell suited for a real-time execution in control applications. The soft\ninequality constraints are integrated by introducing an additional extended\nKalman Filter (EKF) update step using pseudo-measurements. The sequential\nformulation of the algorithm and several developed heuristics ensure both the\nperformance and a low computational effort of the algorithm. A special focus\nlies on an efficient consideration of monotonicity assumptions for GPs in the\nform of inequality constraints. The algorithm is statistically validated in\nsimulations, where the possible advantages in comparison with the standard RGP\nalgorithm become obvious. The paper is concluded with a successful experimental\nvalidation of the developed algorithm for the monotonicity-preserving learning\nof heat transfer values for the control of a vapor compression cycle\nevaporator, leveraging a previously published partial input output\nlinearization (IOL).", "published": "2025-08-20T13:47:08+00:00", "updated": "2025-08-20T13:47:08+00:00", "primary_category": "eess.SY", "categories": ["eess.SY", "cs.SY"], "pdf_url": "http://arxiv.org/pdf/2508.14715v1"}
{"id": "http://arxiv.org/abs/2508.14713v1", "title": "Long-Context Speech Synthesis with Context-Aware Memory", "authors": ["Zhipeng Li", "Xiaofen Xing", "Jingyuan Xing", "Hangrui Hu", "Heng Lu", "Xiangmin Xu"], "summary": "In long-text speech synthesis, current approaches typically convert text to\nspeech at the sentence-level and concatenate the results to form\npseudo-paragraph-level speech. These methods overlook the contextual coherence\nof paragraphs, leading to reduced naturalness and inconsistencies in style and\ntimbre across the long-form speech. To address these issues, we propose a\nContext-Aware Memory (CAM)-based long-context Text-to-Speech (TTS) model. The\nCAM block integrates and retrieves both long-term memory and local context\ndetails, enabling dynamic memory updates and transfers within long paragraphs\nto guide sentence-level speech synthesis. Furthermore, the prefix mask enhances\nthe in-context learning ability by enabling bidirectional attention on prefix\ntokens while maintaining unidirectional generation. Experimental results\ndemonstrate that the proposed method outperforms baseline and state-of-the-art\nlong-context methods in terms of prosody expressiveness, coherence and context\ninference cost across paragraph-level speech.", "published": "2025-08-20T13:43:49+00:00", "updated": "2025-08-20T13:43:49+00:00", "primary_category": "eess.AS", "categories": ["eess.AS", "cs.SD"], "pdf_url": "http://arxiv.org/pdf/2508.14713v1"}
{"id": "http://arxiv.org/abs/2508.14710v1", "title": "Data-Driven Probabilistic Evaluation of Logic Properties with PAC-Confidence on Mealy Machines", "authors": ["Swantje Plambeck", "Ali Salamati", "Eyke Huellermeier", "Goerschwin Fey"], "summary": "Cyber-Physical Systems (CPS) are complex systems that require powerful models\nfor tasks like verification, diagnosis, or debugging. Often, suitable models\nare not available and manual extraction is difficult. Data-driven approaches\nthen provide a solution to, e.g., diagnosis tasks and verification problems\nbased on data collected from the system. In this paper, we consider CPS with a\ndiscrete abstraction in the form of a Mealy machine. We propose a data-driven\napproach to determine the safety probability of the system on a finite horizon\nof n time steps. The approach is based on the Probably Approximately Correct\n(PAC) learning paradigm. Thus, we elaborate a connection between discrete logic\nand probabilistic reachability analysis of systems, especially providing an\nadditional confidence on the determined probability. The learning process\nfollows an active learning paradigm, where new learning data is sampled in a\nguided way after an initial learning set is collected. We validate the approach\nwith a case study on an automated lane-keeping system.", "published": "2025-08-20T13:38:52+00:00", "updated": "2025-08-20T13:38:52+00:00", "primary_category": "cs.AI", "categories": ["cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14710v1"}
{"id": "http://arxiv.org/abs/2508.14709v1", "title": "Improving Resource-Efficient Speech Enhancement via Neural Differentiable DSP Vocoder Refinement", "authors": ["Heitor R. Guimar√£es", "Ke Tan", "Juan Azcarreta", "Jesus Alvarez", "Prabhav Agrawal", "Ashutosh Pandey", "Buye Xu"], "summary": "Deploying speech enhancement (SE) systems in wearable devices, such as smart\nglasses, is challenging due to the limited computational resources on the\ndevice. Although deep learning methods have achieved high-quality results,\ntheir computational cost limits their feasibility on embedded platforms. This\nwork presents an efficient end-to-end SE framework that leverages a\nDifferentiable Digital Signal Processing (DDSP) vocoder for high-quality speech\nsynthesis. First, a compact neural network predicts enhanced acoustic features\nfrom noisy speech: spectral envelope, fundamental frequency (F0), and\nperiodicity. These features are fed into the DDSP vocoder to synthesize the\nenhanced waveform. The system is trained end-to-end with STFT and adversarial\nlosses, enabling direct optimization at the feature and waveform levels.\nExperimental results show that our method improves intelligibility and quality\nby 4% (STOI) and 19% (DNSMOS) over strong baselines without significantly\nincreasing computation, making it well-suited for real-time applications.", "published": "2025-08-20T13:36:28+00:00", "updated": "2025-08-20T13:36:28+00:00", "primary_category": "eess.AS", "categories": ["eess.AS", "cs.SD"], "pdf_url": "http://arxiv.org/pdf/2508.14709v1"}
{"id": "http://arxiv.org/abs/2508.14706v1", "title": "ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine", "authors": ["Junying Chen", "Zhenyang Cai", "Zhiheng Liu", "Yunjin Yang", "Rongsheng Wang", "Qingying Xiao", "Xiangyi Feng", "Zhan Su", "Jing Guo", "Xiang Wan", "Guangjun Yu", "Haizhou Li", "Benyou Wang"], "summary": "Despite the success of large language models (LLMs) in various domains, their\npotential in Traditional Chinese Medicine (TCM) remains largely underexplored\ndue to two critical barriers: (1) the scarcity of high-quality TCM data and (2)\nthe inherently multimodal nature of TCM diagnostics, which involve looking,\nlistening, smelling, and pulse-taking. These sensory-rich modalities are beyond\nthe scope of conventional LLMs. To address these challenges, we present\nShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data\nscarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text\nand 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and\nphysiological signals. ShizhenGPT is pretrained and instruction-tuned to\nachieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect\nrecent national TCM qualification exams and build a visual benchmark for\nMedicinal Recognition and Visual Diagnosis. Experiments demonstrate that\nShizhenGPT outperforms comparable-scale LLMs and competes with larger\nproprietary models. Moreover, it leads in TCM visual understanding among\nexisting multimodal LLMs and demonstrates unified perception across modalities\nlike sound, pulse, smell, and vision, paving the way toward holistic multimodal\nperception and diagnosis in TCM. Datasets, models, and code are publicly\navailable. We hope this work will inspire further exploration in this field.", "published": "2025-08-20T13:30:20+00:00", "updated": "2025-08-20T13:30:20+00:00", "primary_category": "cs.CL", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf_url": "http://arxiv.org/pdf/2508.14706v1"}
{"id": "http://arxiv.org/abs/2508.14705v1", "title": "Learning in Repeated Multi-Objective Stackelberg Games with Payoff Manipulation", "authors": ["Phurinut Srisawad", "Juergen Branke", "Long Tran-Thanh"], "summary": "We study payoff manipulation in repeated multi-objective Stackelberg games,\nwhere a leader may strategically influence a follower's deterministic best\nresponse, e.g., by offering a share of their own payoff. We assume that the\nfollower's utility function, representing preferences over multiple objectives,\nis unknown but linear, and its weight parameter must be inferred through\ninteraction. This introduces a sequential decision-making challenge for the\nleader, who must balance preference elicitation with immediate utility\nmaximisation. We formalise this problem and propose manipulation policies based\non expected utility (EU) and long-term expected utility (longEU), which guide\nthe leader in selecting actions and offering incentives that trade off\nshort-term gains with long-term impact. We prove that under infinite repeated\ninteractions, longEU converges to the optimal manipulation. Empirical results\nacross benchmark environments demonstrate that our approach improves cumulative\nleader utility while promoting mutually beneficial outcomes, all without\nrequiring explicit negotiation or prior knowledge of the follower's utility\nfunction.", "published": "2025-08-20T13:29:24+00:00", "updated": "2025-08-20T13:29:24+00:00", "primary_category": "cs.GT", "categories": ["cs.GT", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14705v1"}
{"id": "http://arxiv.org/abs/2508.14699v1", "title": "Foe for Fraud: Transferable Adversarial Attacks in Credit Card Fraud Detection", "authors": ["Jan Lum Fok", "Qingwen Zeng", "Shiping Chen", "Oscar Fawkes", "Huaming Chen"], "summary": "Credit card fraud detection (CCFD) is a critical application of Machine\nLearning (ML) in the financial sector, where accurately identifying fraudulent\ntransactions is essential for mitigating financial losses. ML models have\ndemonstrated their effectiveness in fraud detection task, in particular with\nthe tabular dataset. While adversarial attacks have been extensively studied in\ncomputer vision and deep learning, their impacts on the ML models, particularly\nthose trained on CCFD tabular datasets, remains largely unexplored. These\nlatent vulnerabilities pose significant threats to the security and stability\nof the financial industry, especially in high-value transactions where losses\ncould be substantial. To address this gap, in this paper, we present a holistic\nframework that investigate the robustness of CCFD ML model against adversarial\nperturbations under different circumstances. Specifically, the gradient-based\nattack methods are incorporated into the tabular credit card transaction data\nin both black- and white-box adversarial attacks settings. Our findings confirm\nthat tabular data is also susceptible to subtle perturbations, highlighting the\nneed for heightened awareness among financial technology practitioners\nregarding ML model security and trustworthiness. Furthermore, the experiments\nby transferring adversarial samples from gradient-based attack method to\nnon-gradient-based models also verify our findings. Our results demonstrate\nthat such attacks remain effective, emphasizing the necessity of developing\nrobust defenses for CCFD algorithms.", "published": "2025-08-20T13:23:28+00:00", "updated": "2025-08-20T13:23:28+00:00", "primary_category": "cs.CR", "categories": ["cs.CR", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14699v1"}
{"id": "http://arxiv.org/abs/2508.14692v1", "title": "Sociotechnical Imaginaries of ChatGPT in Higher Education: The Evolving Media Discourse", "authors": ["Yinan Sun", "Ali Unlu", "Aditya Johri"], "summary": "This study investigates how U.S. news media framed the use of ChatGPT in\nhigher education from November 2022 to October 2024. Employing Framing Theory\nand combining temporal and sentiment analysis of 198 news articles, we trace\nthe evolving narratives surrounding generative AI. We found that the media\ndiscourse largely centered on institutional responses; policy changes and\nteaching practices showed the most consistent presence and positive sentiment\nover time. Conversely, coverage of topics such as human-centered learning, the\njob market, and skill development appeared more sporadically, with initially\nuncertain portrayals gradually shifting toward cautious optimism. Importantly,\nmedia sentiment toward ChatGPT's role in college admissions remained\npredominantly negative. Our findings suggest that media narratives prioritize\ninstitutional responses to generative AI over long-term, broader ethical,\nsocial, and labor-related implications, shaping an emerging sociotechnical\nimaginary that frames generative AI in education primarily through the lens of\nadaptation and innovation.", "published": "2025-08-20T13:17:56+00:00", "updated": "2025-08-20T13:17:56+00:00", "primary_category": "cs.CY", "categories": ["cs.CY"], "pdf_url": "http://arxiv.org/pdf/2508.14692v1"}
{"id": "http://arxiv.org/abs/2508.14689v1", "title": "ECHO: Frequency-aware Hierarchical Encoding for Variable-length Signal", "authors": ["Yucong Zhang", "Juan Liu", "Ming Li"], "summary": "Pre-trained foundation models have demonstrated remarkable success in vision\nand language, yet their potential for general machine signal modeling-covering\nacoustic, vibration, and other industrial sensor data-remains under-explored.\nExisting approach using sub-band-based encoders has achieved competitive\nresults but are limited by fixed input lengths, and the absence of explicit\nfrequency positional encoding. In this work, we propose a novel foundation\nmodel that integrates an advanced band-split architecture with relative\nfrequency positional embeddings, enabling precise spectral localization across\narbitrary sampling configurations. The model supports inputs of arbitrary\nlength without padding or segmentation, producing a concise embedding that\nretains both temporal and spectral fidelity. We evaluate our method on SIREN\n(https://github.com/yucongzh/SIREN), a newly introduced large-scale benchmark\nfor machine signal encoding that unifies multiple datasets, including all DCASE\ntask 2 challenges (2020-2025) and widely-used industrial signal corpora.\nExperimental results demonstrate consistent state-of-the-art performance in\nanomaly detection and fault identification, confirming the effectiveness and\ngeneralization capability of the proposed model. We open-sourced ECHO on\nhttps://github.com/yucongzh/ECHO.", "published": "2025-08-20T13:10:44+00:00", "updated": "2025-08-20T13:10:44+00:00", "primary_category": "cs.SD", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "pdf_url": "http://arxiv.org/pdf/2508.14689v1"}
{"id": "http://arxiv.org/abs/2508.14685v1", "title": "Improving in-context learning with a better scoring function", "authors": ["Omar Naim", "Swarnadeep Bhar", "J√©r√¥me Bolte", "Nicholas Asher"], "summary": "Large language models (LLMs) exhibit a remarkable capacity to learn by\nanalogy, known as in-context learning (ICL). However, recent studies have\nrevealed limitations in this ability. In this paper, we examine these\nlimitations on tasks involving first-order quantifiers such as {\\em all} and\n{\\em some}, as well as on ICL with linear functions. We identify Softmax, the\nscoring function in attention mechanism, as a contributing factor to these\nconstraints. To address this, we propose \\textbf{scaled signed averaging\n(SSA)}, a novel alternative to Softmax. Empirical results show that SSA\ndramatically improves performance on our target tasks. Furthermore, we evaluate\nboth encoder-only and decoder-only transformers models with SSA, demonstrating\nthat they match or exceed their Softmax-based counterparts across a variety of\nlinguistic probing tasks.", "published": "2025-08-20T13:01:34+00:00", "updated": "2025-08-20T13:01:34+00:00", "primary_category": "cs.CL", "categories": ["cs.CL"], "pdf_url": "http://arxiv.org/pdf/2508.14685v1"}
{"id": "http://arxiv.org/abs/2508.14684v1", "title": "Addressing Graph Anomaly Detection via Causal Edge Separation and Spectrum", "authors": ["Zengyi Wo", "Wenjun Wang", "Minglai Shao", "Chang Liu", "Yumeng Wang", "Yueheng Sun"], "summary": "In the real world, anomalous entities often add more legitimate connections\nwhile hiding direct links with other anomalous entities, leading to\nheterophilic structures in anomalous networks that most GNN-based techniques\nfail to address. Several works have been proposed to tackle this issue in the\nspatial domain. However, these methods overlook the complex relationships\nbetween node structure encoding, node features, and their contextual\nenvironment and rely on principled guidance, research on solving spectral\ndomain heterophilic problems remains limited. This study analyzes the spectral\ndistribution of nodes with different heterophilic degrees and discovers that\nthe heterophily of anomalous nodes causes the spectral energy to shift from low\nto high frequencies. To address the above challenges, we propose a spectral\nneural network CES2-GAD based on causal edge separation for anomaly detection\non heterophilic graphs. Firstly, CES2-GAD will separate the original graph into\nhomophilic and heterophilic edges using causal interventions. Subsequently,\nvarious hybrid-spectrum filters are used to capture signals from the segmented\ngraphs. Finally, representations from multiple signals are concatenated and\ninput into a classifier to predict anomalies. Extensive experiments with\nreal-world datasets have proven the effectiveness of the method we proposed.", "published": "2025-08-20T12:59:22+00:00", "updated": "2025-08-20T12:59:22+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14684v1"}
{"id": "http://arxiv.org/abs/2508.14683v1", "title": "Improving Fairness in Graph Neural Networks via Counterfactual Debiasing", "authors": ["Zengyi Wo", "Chang Liu", "Yumeng Wang", "Minglai Shao", "Wenjun Wang"], "summary": "Graph Neural Networks (GNNs) have been successful in modeling\ngraph-structured data. However, similar to other machine learning models, GNNs\ncan exhibit bias in predictions based on attributes like race and gender.\nMoreover, bias in GNNs can be exacerbated by the graph structure and\nmessage-passing mechanisms. Recent cutting-edge methods propose mitigating bias\nby filtering out sensitive information from input or representations, like edge\ndropping or feature masking. Yet, we argue that such strategies may\nunintentionally eliminate non-sensitive features, leading to a compromised\nbalance between predictive accuracy and fairness. To tackle this challenge, we\npresent a novel approach utilizing counterfactual data augmentation for bias\nmitigation. This method involves creating diverse neighborhoods using\ncounterfactuals before message passing, facilitating unbiased node\nrepresentations learning from the augmented graph. Subsequently, an adversarial\ndiscriminator is employed to diminish bias in predictions by conventional GNN\nclassifiers. Our proposed technique, Fair-ICD, ensures the fairness of GNNs\nunder moderate conditions. Experiments on standard datasets using three GNN\nbackbones demonstrate that Fair-ICD notably enhances fairness metrics while\npreserving high predictive performance.", "published": "2025-08-20T12:59:05+00:00", "updated": "2025-08-20T12:59:05+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14683v1"}
{"id": "http://arxiv.org/abs/2508.14682v1", "title": "GeMS: Efficient Gaussian Splatting for Extreme Motion Blur", "authors": ["Gopi Raju Matta", "Trisha Reddypalli", "Vemunuri Divya Madhuri", "Kaushik Mitra"], "summary": "We introduce GeMS, a framework for 3D Gaussian Splatting (3DGS) designed to\nhandle severely motion-blurred images. State-of-the-art deblurring methods for\nextreme blur, such as ExBluRF, as well as Gaussian Splatting-based approaches\nlike Deblur-GS, typically assume access to sharp images for camera pose\nestimation and point cloud generation, an unrealistic assumption. Methods\nrelying on COLMAP initialization, such as BAD-Gaussians, also fail due to\nunreliable feature correspondences under severe blur. To address these\nchallenges, we propose GeMS, a 3DGS framework that reconstructs scenes directly\nfrom extremely blurred images. GeMS integrates: (1) VGGSfM, a deep\nlearning-based Structure-from-Motion pipeline that estimates poses and\ngenerates point clouds directly from blurred inputs; (2) 3DGS-MCMC, which\nenables robust scene initialization by treating Gaussians as samples from a\nprobability distribution, eliminating heuristic densification and pruning; and\n(3) joint optimization of camera trajectories and Gaussian parameters for\nstable reconstruction. While this pipeline produces strong results,\ninaccuracies may remain when all inputs are severely blurred. To mitigate this,\nwe propose GeMS-E, which integrates a progressive refinement step using events:\n(4) Event-based Double Integral (EDI) deblurring restores sharper images that\nare then fed into GeMS, improving pose estimation, point cloud generation, and\noverall reconstruction. Both GeMS and GeMS-E achieve state-of-the-art\nperformance on synthetic and real-world datasets. To our knowledge, this is the\nfirst framework to address extreme motion blur within 3DGS directly from\nseverely blurred inputs.", "published": "2025-08-20T12:55:21+00:00", "updated": "2025-08-20T12:55:21+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14682v1"}
{"id": "http://arxiv.org/abs/2508.14679v1", "title": "Energy-Efficient Routing Algorithm for Wireless Sensor Networks: A Multi-Agent Reinforcement Learning Approach", "authors": ["Parham Soltani", "Mehrshad Eskandarpour", "Amir Ahmadizad", "Hossein Soleimani"], "summary": "Efficient energy management is essential in Wireless Sensor Networks (WSNs)\nto extend network lifetime and ensure reliable data transmission. This paper\npresents a novel method using reinforcement learning-based cluster-head\nselection and a hybrid multi-hop routing algorithm, which leverages Q-learning\nwithin a multi-agent system to dynamically adapt transmission paths based on\nthe energy distribution across sensor nodes. Each sensor node is modeled as an\nautonomous agent that observes local state parameters, such as residual energy,\ndistance to sink, hop count, and hotspot proximity, and selects routing actions\nthat maximize long-term energy efficiency. After computing the optimal paths,\neach sensor aggregates sensed data and forwards it through intermediate nodes\nto a selected transmitter node, chosen based on the highest remaining State of\nCharge (SoC), thereby avoiding premature node depletion. To promote efficient\nlearning, a carefully designed reward function incentivizes balanced load\ndistribution, hotspot avoidance, and energy-aware forwarding while maintaining\nsignal quality. The learning process occurs either in a decentralized manner or\nvia a cloud-based controller that offloads computation in large-scale\ndeployments. Moreover, the RL-driven routing decisions are fused with classical\ngraph-based methods, Minimum Energy Routing Algorithm (MERA) and Minimum\nSpanning Tree (MST), to optimize energy consumption and load balancing.\nSimulations confirm that the proposed approach significantly improves node\nsurvival rate, reduces SoC variance, and enhances network resilience, making it\na scalable and adaptive solution for energy-constrained WSNs in dynamic sensor\ndeployments and IoT applications.", "published": "2025-08-20T12:52:52+00:00", "updated": "2025-08-20T12:52:52+00:00", "primary_category": "cs.NI", "categories": ["cs.NI"], "pdf_url": "http://arxiv.org/pdf/2508.14679v1"}
{"id": "http://arxiv.org/abs/2508.14676v1", "title": "Adaptive Vision-Based Coverage Optimization in Mobile Wireless Sensor Networks: A Multi-Agent Deep Reinforcement Learning Approach", "authors": ["Parham Soltani", "Mehrshad Eskandarpour", "Sina Heidari", "Farnaz Alizadeh", "Hossein Soleimani"], "summary": "Traditional Wireless Sensor Networks (WSNs) typically rely on pre-analysis of\nthe target area, network size, and sensor coverage to determine initial\ndeployment. This often results in significant overlap to ensure continued\nnetwork operation despite sensor energy depletion. With the emergence of Mobile\nWireless Sensor Networks (MWSNs), issues such as sensor failure and static\ncoverage limitations can be more effectively addressed through mobility. This\npaper proposes a novel deployment strategy in which mobile sensors autonomously\nposition themselves to maximize area coverage, eliminating the need for\npredefined policies. A live camera system, combined with deep reinforcement\nlearning (DRL), monitors the network by detecting sensor LED indicators and\nevaluating real-time coverage. Rewards based on coverage efficiency and sensor\nmovement are computed at each learning step and shared across the network\nthrough a Multi-Agent Reinforcement Learning (MARL) framework, enabling\ndecentralized, cooperative sensor control. Key contributions include a\nvision-based, low-cost coverage evaluation method; a scalable MARL-DRL\nframework for autonomous deployment; and a self-reconfigurable system that\nadjusts sensor positioning in response to energy depletion. Compared to\ntraditional distance-based localization, the proposed method achieves a 26.5%\nimprovement in coverage, a 32% reduction in energy consumption, and a 22%\ndecrease in redundancy, extending network lifetime by 45%. This approach\nsignificantly enhances adaptability, energy efficiency, and robustness in\nMWSNs, offering a practical deployment solution within the IoT framework.", "published": "2025-08-20T12:48:21+00:00", "updated": "2025-08-20T12:48:21+00:00", "primary_category": "cs.NI", "categories": ["cs.NI"], "pdf_url": "http://arxiv.org/pdf/2508.14676v1"}
{"id": "http://arxiv.org/abs/2508.14667v1", "title": "ELATE: Evolutionary Language model for Automated Time-series Engineering", "authors": ["Andrew Murray", "Danial Dervovic", "Michael Cashmore"], "summary": "Time-series prediction involves forecasting future values using machine\nlearning models. Feature engineering, whereby existing features are transformed\nto make new ones, is critical for enhancing model performance, but is often\nmanual and time-intensive. Existing automation attempts rely on exhaustive\nenumeration, which can be computationally costly and lacks domain-specific\ninsights. We introduce ELATE (Evolutionary Language model for Automated\nTime-series Engineering), which leverages a language model within an\nevolutionary framework to automate feature engineering for time-series data.\nELATE employs time-series statistical measures and feature importance metrics\nto guide and prune features, while the language model proposes new,\ncontextually relevant feature transformations. Our experiments demonstrate that\nELATE improves forecasting accuracy by an average of 8.4% across various\ndomains.", "published": "2025-08-20T12:36:29+00:00", "updated": "2025-08-20T12:36:29+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14667v1"}
{"id": "http://arxiv.org/abs/2508.14656v1", "title": "Deep Learning for Short Term Equity Trend Forecasting: A Behavior Driven Multi Factor Approach", "authors": ["Yuqi Luan"], "summary": "This study proposes a behaviorally-informed multi-factor stock selection\nframework that integrates short-cycle technical alpha signals with deep\nlearning. We design a dual-task multilayer perceptron (MLP) that jointly\npredicts five-day future returns and directional price movements, thereby\ncapturing nonlinear market behaviors such as volume-price divergence,\nmomentum-driven herding, and bottom reversals. The model is trained on 40\ncarefully constructed factors derived from price-volume patterns and behavioral\nfinance insights. Empirical evaluation demonstrates that the dual-task MLP\nachieves superior and stable performance across both predictive accuracy and\neconomic relevance, as measured by information coefficient (IC), information\nratio (IR), and portfolio backtesting results. Comparative experiments further\nshow that deep learning methods outperform linear baselines by effectively\ncapturing structural interactions between factors. This work highlights the\npotential of structure-aware deep learning in enhancing multi-factor modeling\nand provides a practical framework for short-horizon quantitative investment\nstrategies.", "published": "2025-08-20T12:15:32+00:00", "updated": "2025-08-20T12:15:32+00:00", "primary_category": "q-fin.TR", "categories": ["q-fin.TR"], "pdf_url": "http://arxiv.org/pdf/2508.14656v1"}
{"id": "http://arxiv.org/abs/2508.14654v1", "title": "Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration", "authors": ["Peilin Ji", "Xiao Xue", "Simeng Wang", "Wenhao Yan"], "summary": "In recent years, the increasing frequency of extreme urban rainfall events\nhas posed significant challenges to emergency scheduling systems. Urban\nflooding often leads to severe traffic congestion and service disruptions,\nthreatening public safety and mobility. However, effective decision making\nremains hindered by three key challenges: (1) managing trade-offs among\ncompeting goals (e.g., traffic flow, task completion, and risk mitigation)\nrequires dynamic, context-aware strategies; (2) rapidly evolving environmental\nconditions render static rules inadequate; and (3) LLM-generated strategies\nfrequently suffer from semantic instability and execution inconsistency.\nExisting methods fail to align perception, global optimization, and multi-agent\ncoordination within a unified framework. To tackle these challenges, we\nintroduce H-J, a hierarchical multi-agent framework that integrates\nknowledge-guided prompting, entropy-constrained generation, and feedback-driven\noptimization. The framework establishes a closed-loop pipeline spanning from\nmulti-source perception to strategic execution and continuous refinement. We\nevaluate H-J on real-world urban topology and rainfall data under three\nrepresentative conditions: extreme rainfall, intermittent bursts, and daily\nlight rain. Experiments show that H-J outperforms rule-based and\nreinforcement-learning baselines in traffic smoothness, task success rate, and\nsystem robustness. These findings highlight the promise of uncertainty-aware,\nknowledge-constrained LLM-based approaches for enhancing resilience in urban\nflood response.", "published": "2025-08-20T12:13:03+00:00", "updated": "2025-08-20T12:13:03+00:00", "primary_category": "cs.AI", "categories": ["cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14654v1"}
{"id": "http://arxiv.org/abs/2508.14648v1", "title": "Understanding Data Influence with Differential Approximation", "authors": ["Haoru Tan", "Sitong Wu", "Xiuzhe Wu", "Wang Wang", "Bo Zhao", "Zeke Xie", "Gui-Song Xia", "Xiaojuan Qi"], "summary": "Data plays a pivotal role in the groundbreaking advancements in artificial\nintelligence. The quantitative analysis of data significantly contributes to\nmodel training, enhancing both the efficiency and quality of data utilization.\nHowever, existing data analysis tools often lag in accuracy. For instance, many\nof these tools even assume that the loss function of neural networks is convex.\nThese limitations make it challenging to implement current methods effectively.\nIn this paper, we introduce a new formulation to approximate a sample's\ninfluence by accumulating the differences in influence between consecutive\nlearning steps, which we term Diff-In. Specifically, we formulate the\nsample-wise influence as the cumulative sum of its changes/differences across\nsuccessive training iterations. By employing second-order approximations, we\napproximate these difference terms with high accuracy while eliminating the\nneed for model convexity required by existing methods. Despite being a\nsecond-order method, Diff-In maintains computational complexity comparable to\nthat of first-order methods and remains scalable. This efficiency is achieved\nby computing the product of the Hessian and gradient, which can be efficiently\napproximated using finite differences of first-order gradients. We assess the\napproximation accuracy of Diff-In both theoretically and empirically. Our\ntheoretical analysis demonstrates that Diff-In achieves significantly lower\napproximation error compared to existing influence estimators. Extensive\nexperiments further confirm its superior performance across multiple benchmark\ndatasets in three data-centric tasks: data cleaning, data deletion, and coreset\nselection. Notably, our experiments on data pruning for large-scale\nvision-language pre-training show that Diff-In can scale to millions of data\npoints and outperforms strong baselines.", "published": "2025-08-20T11:59:32+00:00", "updated": "2025-08-20T11:59:32+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14648v1"}
{"id": "http://arxiv.org/abs/2508.14646v1", "title": "OneLoc: Geo-Aware Generative Recommender Systems for Local Life Service", "authors": ["Zhipeng Wei", "Kuo Cai", "Junda She", "Jie Chen", "Minghao Chen", "Yang Zeng", "Qiang Luo", "Wencong Zeng", "Ruiming Tang", "Kun Gai", "Guorui Zhou"], "summary": "Local life service is a vital scenario in Kuaishou App, where video\nrecommendation is intrinsically linked with store's location information. Thus,\nrecommendation in our scenario is challenging because we should take into\naccount user's interest and real-time location at the same time. In the face of\nsuch complex scenarios, end-to-end generative recommendation has emerged as a\nnew paradigm, such as OneRec in the short video scenario, OneSug in the search\nscenario, and EGA in the advertising scenario. However, in local life service,\nan end-to-end generative recommendation model has not yet been developed as\nthere are some key challenges to be solved. The first challenge is how to make\nfull use of geographic information. The second challenge is how to balance\nmultiple objectives, including user interests, the distance between user and\nstores, and some other business objectives. To address the challenges, we\npropose OneLoc. Specifically, we leverage geographic information from different\nperspectives: (1) geo-aware semantic ID incorporates both video and geographic\ninformation for tokenization, (2) geo-aware self-attention in the encoder\nleverages both video location similarity and user's real-time location, and (3)\nneighbor-aware prompt captures rich context information surrounding users for\ngeneration. To balance multiple objectives, we use reinforcement learning and\npropose two reward functions, i.e., geographic reward and GMV reward. With the\nabove design, OneLoc achieves outstanding offline and online performance. In\nfact, OneLoc has been deployed in local life service of Kuaishou App. It serves\n400 million active users daily, achieving 21.016% and 17.891% improvements in\nterms of gross merchandise value (GMV) and orders numbers.", "published": "2025-08-20T11:57:48+00:00", "updated": "2025-08-20T11:57:48+00:00", "primary_category": "cs.IR", "categories": ["cs.IR", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14646v1"}
{"id": "http://arxiv.org/abs/2508.14631v1", "title": "Towards a DSL to Formalize Multimodal Requirements", "authors": ["Marcos Gomez-Vazquez", "Jordi Cabot"], "summary": "Multimodal systems, which process multiple input types such as text, audio,\nand images, are becoming increasingly prevalent in software systems, enabled by\nthe huge advancements in Machine Learning. This triggers the need to easily\ndefine the requirements linked to these new types of user interactions,\npotentially involving more than one modality at the same time. This remains an\nopen challenge due to the lack of languages and methods adapted to the diverse\nnature of multimodal interactions, with the risk of implementing AI-enhanced\nsystems that do not properly satisfy the user needs.\n  In this sense, this paper presents MERLAN, a Domain-Specific Language (DSL)\nto specify the requirements for these new types of multimodal interfaces. We\npresent the metamodel for such language together with a textual syntax\nimplemented as an ANTLR grammar. A prototype tool enabling requirements\nengineers to write such requirements and automatically generate a possible\nimplementation of a system compliant with them on top of an agentic framework\nis also provided.", "published": "2025-08-20T11:40:33+00:00", "updated": "2025-08-20T11:40:33+00:00", "primary_category": "cs.SE", "categories": ["cs.SE"], "pdf_url": "http://arxiv.org/pdf/2508.14631v1"}
{"id": "http://arxiv.org/abs/2508.14627v1", "title": "Clinical semantics for lung cancer prediction", "authors": ["Luis H. John", "Jan A. Kors", "Jenna M. Reps", "Peter R. Rijnbeek", "Egill A. Fridgeirsson"], "summary": "Background: Existing clinical prediction models often represent patient data\nusing features that ignore the semantic relationships between clinical\nconcepts. This study integrates domain-specific semantic information by mapping\nthe SNOMED medical term hierarchy into a low-dimensional hyperbolic space using\nPoincar\\'e embeddings, with the aim of improving lung cancer onset prediction.\n  Methods: Using a retrospective cohort from the Optum EHR dataset, we derived\na clinical knowledge graph from the SNOMED taxonomy and generated Poincar\\'e\nembeddings via Riemannian stochastic gradient descent. These embeddings were\nthen incorporated into two deep learning architectures, a ResNet and a\nTransformer model. Models were evaluated for discrimination (area under the\nreceiver operating characteristic curve) and calibration (average absolute\ndifference between observed and predicted probabilities) performance.\n  Results: Incorporating pre-trained Poincar\\'e embeddings resulted in modest\nand consistent improvements in discrimination performance compared to baseline\nmodels using randomly initialized Euclidean embeddings. ResNet models,\nparticularly those using a 10-dimensional Poincar\\'e embedding, showed enhanced\ncalibration, whereas Transformer models maintained stable calibration across\nconfigurations.\n  Discussion: Embedding clinical knowledge graphs into hyperbolic space and\nintegrating these representations into deep learning models can improve lung\ncancer onset prediction by preserving the hierarchical structure of clinical\nterminologies used for prediction. This approach demonstrates a feasible method\nfor combining data-driven feature extraction with established clinical\nknowledge.", "published": "2025-08-20T11:29:47+00:00", "updated": "2025-08-20T11:29:47+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14627v1"}
{"id": "http://arxiv.org/abs/2508.14624v1", "title": "The revolution in strong lensing discoveries from Euclid", "authors": ["Natalie E. P. Lines", "Tian Li", "Thomas E. Collett", "Philip Holloway", "James W. Nightingale", "Karina Rojas", "Aprajita Verma", "Mike Walmsley"], "summary": "Strong gravitational lensing offers a powerful and direct probe of dark\nmatter, galaxy evolution and cosmology, yet strong lenses are rare: only 1 in\nroughly 10,000 massive galaxies can lens a background source into multiple\nimages. The European Space Agency's Euclid telescope, with its unique\ncombination of high-resolution imaging and wide-area sky coverage, is set to\ntransform this field. In its first quick data release, covering just 0.45% of\nthe full survey area, around 500 high-quality strong lens candidates have been\nidentified using a synergy of machine learning, citizen science and expert\nvisual inspection. This dataset includes exotic systems such as compound lenses\nand edge-on disk lenses, demonstrating Euclid's capacity to probe the lens\nparameter space. The machine learning models developed to discover strong\nlenses in Euclid data are able to find lenses with high purity rates,\nconfirming that the mission's forecast of discovering over 100,000 strong\nlenses is achievable during its 6-year mission. This will increase the number\nof known strong lenses by two orders of magnitude, transforming the science\nthat can be done with strong lensing.", "published": "2025-08-20T11:23:20+00:00", "updated": "2025-08-20T11:23:20+00:00", "primary_category": "astro-ph.GA", "categories": ["astro-ph.GA"], "pdf_url": "http://arxiv.org/pdf/2508.14624v1"}
{"id": "http://arxiv.org/abs/2508.14623v1", "title": "A Study of the Scale Invariant Signal to Distortion Ratio in Speech Separation with Noisy References", "authors": ["Simon Dahl Jepsen", "Mads Gr√¶sb√∏ll Christensen", "Jesper Rindom Jensen"], "summary": "This paper examines the implications of using the Scale-Invariant\nSignal-to-Distortion Ratio (SI-SDR) as both evaluation and training objective\nin supervised speech separation, when the training references contain noise, as\nis the case with the de facto benchmark WSJ0-2Mix. A derivation of the SI-SDR\nwith noisy references reveals that noise limits the achievable SI-SDR, or leads\nto undesired noise in the separated outputs. To address this, a method is\nproposed to enhance references and augment the mixtures with WHAM!, aiming to\ntrain models that avoid learning noisy references. Two models trained on these\nenhanced datasets are evaluated with the non-intrusive NISQA.v2 metric. Results\nshow reduced noise in separated speech but suggest that processing references\nmay introduce artefacts, limiting overall quality gains. Negative correlation\nis found between SI-SDR and perceived noisiness across models on the WSJ0-2Mix\nand Libri2Mix test sets, underlining the conclusion from the derivation.", "published": "2025-08-20T11:22:11+00:00", "updated": "2025-08-20T11:22:11+00:00", "primary_category": "eess.AS", "categories": ["eess.AS", "cs.AI", "cs.SD"], "pdf_url": "http://arxiv.org/pdf/2508.14623v1"}
{"id": "http://arxiv.org/abs/2508.14621v1", "title": "Quantum reservoir computing induced by controllable damping", "authors": ["Emanuele Ricci", "Francesco Monzani", "Luca Nigro", "Enrico Prati"], "summary": "Quantum reservoir computing has emerged as a promising machine learning\nparadigm for processing temporal data on near-term quantum devices, as it\nallows for exploiting the large computational capacity of the qubits without\nsuffering from typical issues that occur when training a variational quantum\ncircuit. In particular, quantum gate-based echo state networks have proven\neffective for learning when the evolution of the reservoir circuit is\nnon-unital. Nonetheless, a method for ensuring a tunable and stable non-unital\nevolution of the circuit was still lacking. We propose an algorithm for\ninducing damping by applying a controlled rotation to each qubit in the\nreservoir. It enables tunable, circuit-level amplitude amplification of the\nzero state, maintaining the system away from the maximally mixed state and\npreventing information loss caused by repeated mid-circuit measurements. The\nalgorithm is inherently stable over time as it can, in principle, process\narbitrarily long input sequences, well beyond the coherence time of individual\nqubits, by inducing an arbitrary damping on each qubit. Moreover, we show that\nquantum correlations between qubits provide an improvement in terms of memory\nretention, underscoring the potential utility of employing a quantum system as\na computational reservoir. We demonstrate, through typical benchmarks for\nreservoir computing, that such an algorithm enables robust and scalable quantum\nrandom computing on fault-tolerant quantum hardware.", "published": "2025-08-20T11:18:57+00:00", "updated": "2025-08-20T11:18:57+00:00", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2508.14621v1"}
{"id": "http://arxiv.org/abs/2508.14618v1", "title": "A Fuzzy-Enhanced Explainable AI Framework for Flight Continuous Descent Operations Classification", "authors": ["Amin Noroozi", "Sandaruwan K. Sethunge", "Elham Norouzi", "Phat T. Phan", "Kavinda U. Waduge", "Md. Arafatur Rahman"], "summary": "Continuous Descent Operations (CDO) involve smooth, idle-thrust descents that\navoid level-offs, reducing fuel burn, emissions, and noise while improving\nefficiency and passenger comfort. Despite its operational and environmental\nbenefits, limited research has systematically examined the factors influencing\nCDO performance. Moreover, many existing methods in related areas, such as\ntrajectory optimization, lack the transparency required in aviation, where\nexplainability is critical for safety and stakeholder trust. This study\naddresses these gaps by proposing a Fuzzy-Enhanced Explainable AI (FEXAI)\nframework that integrates fuzzy logic with machine learning and SHapley\nAdditive exPlanations (SHAP) analysis. For this purpose, a comprehensive\ndataset of 29 features, including 11 operational and 18 weather-related\nfeatures, was collected from 1,094 flights using Automatic Dependent\nSurveillance-Broadcast (ADS-B) data. Machine learning models and SHAP were then\napplied to classify flights' CDO adherence levels and rank features by\nimportance. The three most influential features, as identified by SHAP scores,\nwere then used to construct a fuzzy rule-based classifier, enabling the\nextraction of interpretable fuzzy rules. All models achieved classification\naccuracies above 90%, with FEXAI providing meaningful, human-readable rules for\noperational users. Results indicated that the average descent rate within the\narrival route, the number of descent segments, and the average change in\ndirectional heading during descent were the strongest predictors of CDO\nperformance. The FEXAI method proposed in this study presents a novel pathway\nfor operational decision support and could be integrated into aviation tools to\nenable real-time advisories that maintain CDO adherence under varying\noperational conditions.", "published": "2025-08-20T11:08:16+00:00", "updated": "2025-08-20T11:08:16+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14618v1"}
{"id": "http://arxiv.org/abs/2508.14615v1", "title": "Measuring IIA Violations in Similarity Choices with Bayesian Models", "authors": ["Hugo Sales Corr√™a", "Suryanarayana Sankagiri", "Daniel Ratton Figueiredo", "Matthias Grossglauser"], "summary": "Similarity choice data occur when humans make choices among alternatives\nbased on their similarity to a target, e.g., in the context of information\nretrieval and in embedding learning settings. Classical metric-based models of\nsimilarity choice assume independence of irrelevant alternatives (IIA), a\nproperty that allows for a simpler formulation. While IIA violations have been\ndetected in many discrete choice settings, the similarity choice setting has\nreceived scant attention. This is because the target-dependent nature of the\nchoice complicates IIA testing. We propose two statistical methods to test for\nIIA: a classical goodness-of-fit test and a Bayesian counterpart based on the\nframework of Posterior Predictive Checks (PPC). This Bayesian approach, our\nmain technical contribution, quantifies the degree of IIA violation beyond its\nmere significance. We curate two datasets: one with choice sets designed to\nelicit IIA violations, and another with randomly generated choice sets from the\nsame item universe. Our tests confirmed significant IIA violations on both\ndatasets, and notably, we find a comparable degree of violation between them.\nFurther, we devise a new PPC test for population homogeneity. Results show that\nthe population is indeed homogenous, suggesting that the IIA violations are\ndriven by context effects -- specifically, interactions within the choice sets.\nThese results highlight the need for new similarity choice models that account\nfor such context effects.", "published": "2025-08-20T11:02:26+00:00", "updated": "2025-08-20T11:02:26+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "stat.ML", "I.2.6"], "pdf_url": "http://arxiv.org/pdf/2508.14615v1"}
{"id": "http://arxiv.org/abs/2508.14613v1", "title": "A Simple and Scalable Kernel Density Approach for Reliable Uncertainty Quantification in Atomistic Machine Learning", "authors": ["Daniel Willimetz", "Luk√°≈° Grajciar"], "summary": "Machine learning models are increasingly used to predict material properties\nand accelerate atomistic simulations, but the reliability of their predictions\ndepends on the representativeness of the training data. We present a scalable,\nGPU-accelerated uncertainty quantification framework based on\n$k$-nearest-neighbor kernel density estimation (KDE) in a PCA-reduced\ndescriptor space. This method efficiently detects sparsely sampled regions in\nlarge, high-dimensional datasets and provides a transferable, model-agnostic\nuncertainty metric without requiring retraining costly model ensembles. The\nframework is validated across diverse case studies varying in: i) chemistry,\nii) prediction models (including foundational neural network), iii) descriptors\nused for KDE estimation, and iv) properties whose uncertainty is sought. In all\ncases, the KDE-based score reliably flags extrapolative configurations,\ncorrelates well with conventional ensemble-based uncertainties, and highlights\nregions of reduced prediction trustworthiness. The approach offers a practical\nroute for improving the interpretability, robustness, and deployment readiness\nof ML models in materials science.", "published": "2025-08-20T10:58:17+00:00", "updated": "2025-08-20T10:58:17+00:00", "primary_category": "physics.chem-ph", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/2508.14613v1"}
{"id": "http://arxiv.org/abs/2508.14600v1", "title": "DualNILM: Energy Injection Identification Enabled Disaggregation with Deep Multi-Task Learning", "authors": ["Xudong Wang", "Guoming Tang", "Junyu Xue", "Srinivasan Keshav", "Tongxin Li", "Chris Ding"], "summary": "Non-Intrusive Load Monitoring (NILM) offers a cost-effective method to obtain\nfine-grained appliance-level energy consumption in smart homes and building\napplications. However, the increasing adoption of behind-the-meter energy\nsources, such as solar panels and battery storage, poses new challenges for\nconventional NILM methods that rely solely on at-the-meter data. The injected\nenergy from the behind-the-meter sources can obscure the power signatures of\nindividual appliances, leading to a significant decline in NILM performance. To\naddress this challenge, we present DualNILM, a deep multi-task learning\nframework designed for the dual tasks of appliance state recognition and\ninjected energy identification in NILM. By integrating sequence-to-point and\nsequence-to-sequence strategies within a Transformer-based architecture,\nDualNILM can effectively capture multi-scale temporal dependencies in the\naggregate power consumption patterns, allowing for accurate appliance state\nrecognition and energy injection identification. We conduct validation of\nDualNILM using both self-collected and synthesized open NILM datasets that\ninclude both appliance-level energy consumption and energy injection. Extensive\nexperimental results demonstrate that DualNILM maintains an excellent\nperformance for the dual tasks in NILM, much outperforming conventional\nmethods.", "published": "2025-08-20T10:35:38+00:00", "updated": "2025-08-20T10:35:38+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "eess.SP", "I.2.6; J.7; I.5.4"], "pdf_url": "http://arxiv.org/pdf/2508.14600v1"}
{"id": "http://arxiv.org/abs/2508.14599v1", "title": "Incremental Object Detection with Prompt-based Methods", "authors": ["Matthias Neuwirth-Trapp", "Maarten Bieshaar", "Danda Pani Paudel", "Luc Van Gool"], "summary": "Visual prompt-based methods have seen growing interest in incremental\nlearning (IL) for image classification. These approaches learn additional\nembedding vectors while keeping the model frozen, making them efficient to\ntrain. However, no prior work has applied such methods to incremental object\ndetection (IOD), leaving their generalizability unclear. In this paper, we\nanalyze three different prompt-based methods under a complex domain-incremental\nlearning setting. We additionally provide a wide range of reference baselines\nfor comparison. Empirically, we show that the prompt-based approaches we tested\nunderperform in this setting. However, a strong yet practical method, combining\nvisual prompts with replaying a small portion of previous data, achieves the\nbest results. Together with additional experiments on prompt length and\ninitialization, our findings offer valuable insights for advancing prompt-based\nIL in IOD.", "published": "2025-08-20T10:34:31+00:00", "updated": "2025-08-20T10:34:31+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14599v1"}
{"id": "http://arxiv.org/abs/2508.14597v1", "title": "Reliable Smoke Detection via Optical Flow-Guided Feature Fusion and Transformer-Based Uncertainty Modeling", "authors": ["Nitish Kumar Mahala", "Muzammil Khan", "Pushpendra Kumar"], "summary": "Fire outbreaks pose critical threats to human life and infrastructure,\nnecessitating high-fidelity early-warning systems that detect combustion\nprecursors such as smoke. However, smoke plumes exhibit complex spatiotemporal\ndynamics influenced by illumination variability, flow kinematics, and\nenvironmental noise, undermining the reliability of traditional detectors. To\naddress these challenges without the logistical complexity of multi-sensor\narrays, we propose an information-fusion framework by integrating smoke feature\nrepresentations extracted from monocular imagery. Specifically, a Two-Phase\nUncertainty-Aware Shifted Windows Transformer for robust and reliable smoke\ndetection, leveraging a novel smoke segmentation dataset, constructed via\noptical flow-based motion encoding, is proposed. The optical flow estimation is\nperformed with a four-color-theorem-inspired dual-phase level-set\nfractional-order variational model, which preserves motion discontinuities. The\nresulting color-encoded optical flow maps are fused with appearance cues via a\nGaussian Mixture Model to generate binary segmentation masks of the smoke\nregions. These fused representations are fed into the novel Shifted-Windows\nTransformer, which is augmented with a multi-scale uncertainty estimation head\nand trained under a two-phase learning regimen. First learning phase optimizes\nsmoke detection accuracy, while during the second phase, the model learns to\nestimate plausibility confidence in its predictions by jointly modeling\naleatoric and epistemic uncertainties. Extensive experiments using multiple\nevaluation metrics and comparative analysis with state-of-the-art approaches\ndemonstrate superior generalization and robustness, offering a reliable\nsolution for early fire detection in surveillance, industrial safety, and\nautonomous monitoring applications.", "published": "2025-08-20T10:28:53+00:00", "updated": "2025-08-20T10:28:53+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14597v1"}
{"id": "http://arxiv.org/abs/2508.14588v1", "title": "Controllable Latent Space Augmentation for Digital Pathology", "authors": ["Sofi√®ne Boutaj", "Marin Scalbert", "Pierre Marza", "Florent Couzinie-Devy", "Maria Vakalopoulou", "Stergios Christodoulidis"], "summary": "Whole slide image (WSI) analysis in digital pathology presents unique\nchallenges due to the gigapixel resolution of WSIs and the scarcity of dense\nsupervision signals. While Multiple Instance Learning (MIL) is a natural fit\nfor slide-level tasks, training robust models requires large and diverse\ndatasets. Even though image augmentation techniques could be utilized to\nincrease data variability and reduce overfitting, implementing them effectively\nis not a trivial task. Traditional patch-level augmentation is prohibitively\nexpensive due to the large number of patches extracted from each WSI, and\nexisting feature-level augmentation methods lack control over transformation\nsemantics. We introduce HistAug, a fast and efficient generative model for\ncontrollable augmentations in the latent space for digital pathology. By\nconditioning on explicit patch-level transformations (e.g., hue, erosion),\nHistAug generates realistic augmented embeddings while preserving initial\nsemantic information. Our method allows the processing of a large number of\npatches in a single forward pass efficiently, while at the same time\nconsistently improving MIL model performance. Experiments across multiple\nslide-level tasks and diverse organs show that HistAug outperforms existing\nmethods, particularly in low-data regimes. Ablation studies confirm the\nbenefits of learned transformations over noise-based perturbations and\nhighlight the importance of uniform WSI-wise augmentation. Code is available at\nhttps://github.com/MICS-Lab/HistAug.", "published": "2025-08-20T10:11:48+00:00", "updated": "2025-08-20T10:11:48+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14588v1"}
{"id": "http://arxiv.org/abs/2508.14586v1", "title": "Filling the Gap for Uzbek: Creating Translation Resources for Southern Uzbek", "authors": ["Mukhammadsaid Mamasaidov", "Azizullah Aral", "Abror Shopulatov", "Mironshoh Inomjonov"], "summary": "Southern Uzbek (uzs) is a Turkic language variety spoken by around 5 million\npeople in Afghanistan and differs significantly from Northern Uzbek (uzn) in\nphonology, lexicon, and orthography. Despite the large number of speakers,\nSouthern Uzbek is underrepresented in natural language processing. We present\nnew resources for Southern Uzbek machine translation, including a 997-sentence\nFLORES+ dev set, 39,994 parallel sentences from dictionary, literary, and web\nsources, and a fine-tuned NLLB-200 model (lutfiy). We also propose a\npost-processing method for restoring Arabic-script half-space characters, which\nimproves handling of morphological boundaries. All datasets, models, and tools\nare released publicly to support future work on Southern Uzbek and other\nlow-resource languages.", "published": "2025-08-20T10:05:57+00:00", "updated": "2025-08-20T10:05:57+00:00", "primary_category": "cs.CL", "categories": ["cs.CL"], "pdf_url": "http://arxiv.org/pdf/2508.14586v1"}
{"id": "http://arxiv.org/abs/2508.14576v1", "title": "A Comprehensive Evaluation of the Sensitivity of Density-Ratio Estimation Based Fairness Measurement in Regression", "authors": ["Abdalwahab Almajed", "Maryam Tabar", "Peyman Najafirad"], "summary": "The prevalence of algorithmic bias in Machine Learning (ML)-driven approaches\nhas inspired growing research on measuring and mitigating bias in the ML\ndomain. Accordingly, prior research studied how to measure fairness in\nregression which is a complex problem. In particular, recent research proposed\nto formulate it as a density-ratio estimation problem and relied on a Logistic\nRegression-driven probabilistic classifier-based approach to solve it. However,\nthere are several other methods to estimate a density ratio, and to the best of\nour knowledge, prior work did not study the sensitivity of such fairness\nmeasurement methods to the choice of underlying density ratio estimation\nalgorithm. To fill this gap, this paper develops a set of fairness measurement\nmethods with various density-ratio estimation cores and thoroughly investigates\nhow different cores would affect the achieved level of fairness. Our\nexperimental results show that the choice of density-ratio estimation core\ncould significantly affect the outcome of fairness measurement method, and\neven, generate inconsistent results with respect to the relative fairness of\nvarious algorithms. These observations suggest major issues with density-ratio\nestimation based fairness measurement in regression and a need for further\nresearch to enhance their reliability.", "published": "2025-08-20T09:54:55+00:00", "updated": "2025-08-20T09:54:55+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14576v1"}
{"id": "http://arxiv.org/abs/2508.14574v1", "title": "Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning", "authors": ["Guilhem Faur√©", "Mostafa Sadeghi", "Sam Bigeard", "Slim Ouni"], "summary": "One of the main challenges in neural sign language production (SLP) lies in\nthe high intra-class variability of signs, arising from signer morphology and\nstylistic variety in the training data. To improve robustness to such\nvariations, we propose two enhancements to the standard Progressive\nTransformers (PT) architecture (Saunders et al., 2020). First, we encode poses\nusing bone rotations in quaternion space and train with a geodesic loss to\nimprove the accuracy and clarity of angular joint movements. Second, we\nintroduce a contrastive loss to structure decoder embeddings by semantic\nsimilarity, using either gloss overlap or SBERT-based sentence similarity,\naiming to filter out anatomical and stylistic features that do not convey\nrelevant semantic information. On the Phoenix14T dataset, the contrastive loss\nalone yields a 16% improvement in Probability of Correct Keypoint over the PT\nbaseline. When combined with quaternion-based pose encoding, the model achieves\na 6% reduction in Mean Bone Angle Error. These results point to the benefit of\nincorporating skeletal structure modeling and semantically guided contrastive\nobjectives on sign pose representations into the training of Transformer-based\nSLP models.", "published": "2025-08-20T09:52:51+00:00", "updated": "2025-08-20T09:52:51+00:00", "primary_category": "cs.CL", "categories": ["cs.CL", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14574v1"}
{"id": "http://arxiv.org/abs/2508.14567v1", "title": "Safety-Critical Learning for Long-Tail Events: The TUM Traffic Accident Dataset", "authors": ["Walter Zimmer", "Ross Greer", "Xingcheng Zhou", "Rui Song", "Marc Pavel", "Daniel Lehmberg", "Ahmed Ghita", "Akshay Gopalkrishnan", "Mohan Trivedi", "Alois Knoll"], "summary": "Even though a significant amount of work has been done to increase the safety\nof transportation networks, accidents still occur regularly. They must be\nunderstood as an unavoidable and sporadic outcome of traffic networks. We\npresent the TUM Traffic Accident (TUMTraf-A) dataset, a collection of\nreal-world highway accidents. It contains ten sequences of vehicle crashes at\nhigh-speed driving with 294,924 labeled 2D and 93,012 labeled 3D boxes and\ntrack IDs within 48,144 labeled frames recorded from four roadside cameras and\nLiDARs at 10 Hz. The dataset contains ten object classes and is provided in the\nOpenLABEL format. We propose Accid3nD, an accident detection model that\ncombines a rule-based approach with a learning-based one. Experiments and\nablation studies on our dataset show the robustness of our proposed method. The\ndataset, model, and code are available on our project website:\nhttps://tum-traffic-dataset.github.io/tumtraf-a.", "published": "2025-08-20T09:38:50+00:00", "updated": "2025-08-20T09:38:50+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14567v1"}
{"id": "http://arxiv.org/abs/2508.14565v1", "title": "Cooperative SGD with Dynamic Mixing Matrices", "authors": ["Soumya Sarkar", "Shweta Jain"], "summary": "One of the most common methods to train machine learning algorithms today is\nthe stochastic gradient descent (SGD). In a distributed setting, SGD-based\nalgorithms have been shown to converge theoretically under specific\ncircumstances. A substantial number of works in the distributed SGD setting\nassume a fixed topology for the edge devices. These papers also assume that the\ncontribution of nodes to the global model is uniform. However, experiments have\nshown that such assumptions are suboptimal and a non uniform aggregation\nstrategy coupled with a dynamically shifting topology and client selection can\nsignificantly improve the performance of such models. This paper details a\nunified framework that covers several Local-Update SGD-based distributed\nalgorithms with dynamic topologies and provides improved or matching\ntheoretical guarantees on convergence compared to existing work.", "published": "2025-08-20T09:37:07+00:00", "updated": "2025-08-20T09:37:07+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.DC"], "pdf_url": "http://arxiv.org/pdf/2508.14565v1"}
{"id": "http://arxiv.org/abs/2508.14562v1", "title": "Locality-aware Concept Bottleneck Model", "authors": ["Sujin Jeon", "Hyundo Lee", "Eungseo Kim", "Sanghack Lee", "Byoung-Tak Zhang", "Inwoo Hwang"], "summary": "Concept bottleneck models (CBMs) are inherently interpretable models that\nmake predictions based on human-understandable visual cues, referred to as\nconcepts. As obtaining dense concept annotations with human labeling is\ndemanding and costly, recent approaches utilize foundation models to determine\nthe concepts existing in the images. However, such label-free CBMs often fail\nto localize concepts in relevant regions, attending to visually unrelated\nregions when predicting concept presence. To this end, we propose a framework,\ncoined Locality-aware Concept Bottleneck Model (LCBM), which utilizes rich\ninformation from foundation models and adopts prototype learning to ensure\naccurate spatial localization of the concepts. Specifically, we assign one\nprototype to each concept, promoted to represent a prototypical image feature\nof that concept. These prototypes are learned by encouraging them to encode\nsimilar local regions, leveraging foundation models to assure the relevance of\neach prototype to its associated concept. Then we use the prototypes to\nfacilitate the learning process of identifying the proper local region from\nwhich each concept should be predicted. Experimental results demonstrate that\nLCBM effectively identifies present concepts in the images and exhibits\nimproved localization while maintaining comparable classification performance.", "published": "2025-08-20T09:33:48+00:00", "updated": "2025-08-20T09:33:48+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14562v1"}
{"id": "http://arxiv.org/abs/2508.14558v1", "title": "A Comprehensive Review of Agricultural Parcel and Boundary Delineation from Remote Sensing Images: Recent Progress and Future Perspectives", "authors": ["Juepeng Zheng", "Zi Ye", "Yibin Wen", "Jianxi Huang", "Zhiwei Zhang", "Qingmei Li", "Qiong Hu", "Baodong Xu", "Lingyuan Zhao", "Haohuan Fu"], "summary": "Powered by advances in multiple remote sensing sensors, the production of\nhigh spatial resolution images provides great potential to achieve\ncost-efficient and high-accuracy agricultural inventory and analysis in an\nautomated way. Lots of studies that aim at providing an inventory of the level\nof each agricultural parcel have generated many methods for Agricultural Parcel\nand Boundary Delineation (APBD). This review covers APBD methods for detecting\nand delineating agricultural parcels and systematically reviews the past and\npresent of APBD-related research applied to remote sensing images. With the\ngoal to provide a clear knowledge map of existing APBD efforts, we conduct a\ncomprehensive review of recent APBD papers to build a meta-data analysis,\nincluding the algorithm, the study site, the crop type, the sensor type, the\nevaluation method, etc. We categorize the methods into three classes: (1)\ntraditional image processing methods (including pixel-based, edge-based and\nregion-based); (2) traditional machine learning methods (such as random forest,\ndecision tree); and (3) deep learning-based methods. With deep\nlearning-oriented approaches contributing to a majority, we further discuss\ndeep learning-based methods like semantic segmentation-based, object\ndetection-based and Transformer-based methods. In addition, we discuss five\nAPBD-related issues to further comprehend the APBD domain using remote sensing\ndata, such as multi-sensor data in APBD task, comparisons between single-task\nlearning and multi-task learning in the APBD domain, comparisons among\ndifferent algorithms and different APBD tasks, etc. Finally, this review\nproposes some APBD-related applications and a few exciting prospects and\npotential hot topics in future APBD research. We hope this review help\nresearchers who involved in APBD domain to keep track of its development and\ntendency.", "published": "2025-08-20T09:24:42+00:00", "updated": "2025-08-20T09:24:42+00:00", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2508.14558v1"}
{"id": "http://arxiv.org/abs/2508.14557v1", "title": "Improving OCR using internal document redundancy", "authors": ["Diego Belzarena", "Seginus Mowlavi", "Aitor Artola", "Camilo Mari√±o", "Marina Gardella", "Ignacio Ram√≠rez", "Antoine Tadros", "Roy He", "Natalia Bottaioli", "Boshra Rajaei", "Gregory Randall", "Jean-Michel Morel"], "summary": "Current OCR systems are based on deep learning models trained on large\namounts of data. Although they have shown some ability to generalize to unseen\ndata, especially in detection tasks, they can struggle with recognizing\nlow-quality data. This is particularly evident for printed documents, where\nintra-domain data variability is typically low, but inter-domain data\nvariability is high. In that context, current OCR methods do not fully exploit\neach document's redundancy. We propose an unsupervised method by leveraging the\nredundancy of character shapes within a document to correct imperfect outputs\nof a given OCR system and suggest better clustering. To this aim, we introduce\nan extended Gaussian Mixture Model (GMM) by alternating an\nExpectation-Maximization (EM) algorithm with an intra-cluster realignment\nprocess and normality statistical testing. We demonstrate improvements in\ndocuments with various levels of degradation, including recovered Uruguayan\nmilitary archives and 17th to mid-20th century European newspapers.", "published": "2025-08-20T09:21:43+00:00", "updated": "2025-08-20T09:21:43+00:00", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2508.14557v1"}
{"id": "http://arxiv.org/abs/2508.14552v1", "title": "From Slices to Structures: Unsupervised 3D Reconstruction of Female Pelvic Anatomy from Freehand Transvaginal Ultrasound", "authors": ["Max Kr√§henmann", "Sergio Tascon-Morales", "Fabian Laumer", "Julia E. Vogt", "Ece Ozkan"], "summary": "Volumetric ultrasound has the potential to significantly improve diagnostic\naccuracy and clinical decision-making, yet its widespread adoption remains\nlimited by dependence on specialized hardware and restrictive acquisition\nprotocols. In this work, we present a novel unsupervised framework for\nreconstructing 3D anatomical structures from freehand 2D transvaginal\nultrasound (TVS) sweeps, without requiring external tracking or learned pose\nestimators. Our method adapts the principles of Gaussian Splatting to the\ndomain of ultrasound, introducing a slice-aware, differentiable rasterizer\ntailored to the unique physics and geometry of ultrasound imaging. We model\nanatomy as a collection of anisotropic 3D Gaussians and optimize their\nparameters directly from image-level supervision, leveraging sensorless probe\nmotion estimation and domain-specific geometric priors. The result is a\ncompact, flexible, and memory-efficient volumetric representation that captures\nanatomical detail with high spatial fidelity. This work demonstrates that\naccurate 3D reconstruction from 2D ultrasound images can be achieved through\npurely computational means, offering a scalable alternative to conventional 3D\nsystems and enabling new opportunities for AI-assisted analysis and diagnosis.", "published": "2025-08-20T09:09:06+00:00", "updated": "2025-08-20T09:09:06+00:00", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14552v1"}
{"id": "http://arxiv.org/abs/2508.14544v1", "title": "Adaptively Robust LLM Inference Optimization under Prediction Uncertainty", "authors": ["Zixi Chen", "Yinyu Ye", "Zijie Zhou"], "summary": "We study the problem of optimizing Large Language Model (LLM) inference\nscheduling to minimize total latency. LLM inference is an online and multi-task\nservice process and also heavily energy consuming by which a pre-trained LLM\nprocesses input requests and generates output tokens sequentially. Therefore,\nit is vital to improve its scheduling efficiency and reduce the power\nconsumption while a great amount of prompt requests are arriving. A key\nchallenge in LLM inference scheduling is that while the prompt length is known\nupon arrival, the output length, which critically impacts memory usage and\nprocessing time, is unknown. To address this uncertainty, we propose algorithms\nthat leverage machine learning to predict output lengths, assuming the\nprediction provides an interval classification (min-max range) for each\nrequest.\n  We first design a conservative algorithm, $\\mathcal{A}_{\\max}$, which\nschedules requests based on the upper bound of predicted output lengths to\nprevent memory overflow. However, this approach is overly conservative: as\nprediction accuracy decreases, performance degrades significantly due to\npotential overestimation. To overcome this limitation, we propose\n$\\mathcal{A}_{\\min}$, an adaptive algorithm that initially treats the predicted\nlower bound as the output length and dynamically refines this estimate during\ninferencing. We prove that $\\mathcal{A}_{\\min}$ achieves a log-scale\ncompetitive ratio. Through numerical simulations, we demonstrate that\n$\\mathcal{A}_{\\min}$ often performs nearly as well as the hindsight scheduler,\nhighlighting both its efficiency and robustness in practical scenarios.\nMoreover, $\\mathcal{A}_{\\min}$ relies solely on the lower bound of the\nprediction interval--an advantageous design choice since upper bounds on output\nlength are typically more challenging to predict accurately.", "published": "2025-08-20T08:55:26+00:00", "updated": "2025-08-20T08:55:26+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf_url": "http://arxiv.org/pdf/2508.14544v1"}
{"id": "http://arxiv.org/abs/2508.14542v1", "title": "Taming VR Teleoperation and Learning from Demonstration for Multi-Task Bimanual Table Service Manipulation", "authors": ["Weize Li", "Zhengxiao Han", "Lixin Xu", "Xiangyu Chen", "Harrison Bounds", "Chenrui Zhang", "Yifan Xu"], "summary": "This technical report presents the champion solution of the Table Service\nTrack in the ICRA 2025 What Bimanuals Can Do (WBCD) competition. We tackled a\nseries of demanding tasks under strict requirements for speed, precision, and\nreliability: unfolding a tablecloth (deformable-object manipulation), placing a\npizza onto the table (pick-and-place), and opening and closing a food container\nwith the lid. Our solution combines VR-based teleoperation and Learning from\nDemonstrations (LfD) to balance robustness and autonomy. Most subtasks were\nexecuted through high-fidelity remote teleoperation, while the pizza placement\nwas handled by an ACT-based policy trained from 100 in-person teleoperated\ndemonstrations with randomized initial configurations. By carefully integrating\nscoring rules, task characteristics, and current technical capabilities, our\napproach achieved both high efficiency and reliability, ultimately securing the\nfirst place in the competition.", "published": "2025-08-20T08:47:40+00:00", "updated": "2025-08-20T08:47:40+00:00", "primary_category": "cs.RO", "categories": ["cs.RO"], "pdf_url": "http://arxiv.org/pdf/2508.14542v1"}
{"id": "http://arxiv.org/abs/2508.14539v1", "title": "FedEve: On Bridging the Client Drift and Period Drift for Cross-device Federated Learning", "authors": ["Tao Shen", "Zexi Li", "Didi Zhu", "Ziyu Zhao", "Chao Wu", "Fei Wu"], "summary": "Federated learning (FL) is a machine learning paradigm that allows multiple\nclients to collaboratively train a shared model without exposing their private\ndata. Data heterogeneity is a fundamental challenge in FL, which can result in\npoor convergence and performance degradation. Client drift has been recognized\nas one of the factors contributing to this issue resulting from the multiple\nlocal updates in FedAvg. However, in cross-device FL, a different form of drift\narises due to the partial client participation, but it has not been studied\nwell. This drift, we referred as period drift, occurs as participating clients\nat each communication round may exhibit distinct data distribution that\ndeviates from that of all clients. It could be more harmful than client drift\nsince the optimization objective shifts with every round.\n  In this paper, we investigate the interaction between period drift and client\ndrift, finding that period drift can have a particularly detrimental effect on\ncross-device FL as the degree of data heterogeneity increases. To tackle these\nissues, we propose a predict-observe framework and present an instantiated\nmethod, FedEve, where these two types of drift can compensate each other to\nmitigate their overall impact. We provide theoretical evidence that our\napproach can reduce the variance of model updates. Extensive experiments\ndemonstrate that our method outperforms alternatives on non-iid data in\ncross-device settings.", "published": "2025-08-20T08:42:34+00:00", "updated": "2025-08-20T08:42:34+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.DC"], "pdf_url": "http://arxiv.org/pdf/2508.14539v1"}
{"id": "http://arxiv.org/abs/2508.14536v1", "title": "Beyond ReLU: Chebyshev-DQN for Enhanced Deep Q-Networks", "authors": ["Saman Yazdannik", "Morteza Tayefi", "Shamim Sanisales"], "summary": "The performance of Deep Q-Networks (DQN) is critically dependent on the\nability of its underlying neural network to accurately approximate the\naction-value function. Standard function approximators, such as multi-layer\nperceptrons, may struggle to efficiently represent the complex value landscapes\ninherent in many reinforcement learning problems. This paper introduces a novel\narchitecture, the Chebyshev-DQN (Ch-DQN), which integrates a Chebyshev\npolynomial basis into the DQN framework to create a more effective feature\nrepresentation. By leveraging the powerful function approximation properties of\nChebyshev polynomials, we hypothesize that the Ch-DQN can learn more\nefficiently and achieve higher performance. We evaluate our proposed model on\nthe CartPole-v1 benchmark and compare it against a standard DQN with a\ncomparable number of parameters. Our results demonstrate that the Ch-DQN with a\nmoderate polynomial degree (N=4) achieves significantly better asymptotic\nperformance, outperforming the baseline by approximately 39\\%. However, we also\nfind that the choice of polynomial degree is a critical hyperparameter, as a\nhigh degree (N=8) can be detrimental to learning. This work validates the\npotential of using orthogonal polynomial bases in deep reinforcement learning\nwhile also highlighting the trade-offs involved in model complexity.", "published": "2025-08-20T08:41:15+00:00", "updated": "2025-08-20T08:41:15+00:00", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2508.14536v1"}
{"id": "http://arxiv.org/abs/2508.14530v1", "title": "DOPA: Stealthy and Generalizable Backdoor Attacks from a Single Client under Challenging Federated Constraints", "authors": ["Xuezheng Qin", "Ruwei Huang", "Xiaolong Tang", "Feng Li"], "summary": "Federated Learning (FL) is increasingly adopted for privacy-preserving\ncollaborative training, but its decentralized nature makes it particularly\nsusceptible to backdoor attacks. Existing attack methods, however, often rely\non idealized assumptions and fail to remain effective under real-world\nconstraints, such as limited attacker control, non-IID data distributions, and\nthe presence of diverse defense mechanisms. To address this gap, we propose\nDOPA (Divergent Optimization Path Attack), a novel framework that simulates\nheterogeneous local training dynamics and seeks consensus across divergent\noptimization trajectories to craft universally effective and stealthy backdoor\ntriggers. By leveraging consistency signals across simulated paths to guide\noptimization, DOPA overcomes the challenge of heterogeneity-induced instability\nand achieves practical attack viability under stringent federated constraints.\nWe validate DOPA on a comprehensive suite of 12 defense strategies, two model\narchitectures (ResNet18/VGG16), two datasets (CIFAR-10/TinyImageNet), and both\nmild and extreme non-IID settings. Despite operating under a single-client,\nblack-box, and sparsely participating threat model, DOPA consistently achieves\nhigh attack success, minimal accuracy degradation, low runtime, and long-term\npersistence. These results demonstrate a more practical attack paradigm,\noffering new perspectives for designing robust defense strategies in federated\nlearning systems", "published": "2025-08-20T08:39:12+00:00", "updated": "2025-08-20T08:39:12+00:00", "primary_category": "cs.CR", "categories": ["cs.CR"], "pdf_url": "http://arxiv.org/pdf/2508.14530v1"}
{"id": "http://arxiv.org/abs/2508.14528v1", "title": "A $(4/3+\\varepsilon)$-Approximation for Preemptive Scheduling with Batch Setup Times", "authors": ["Max A. Deppert", "David Fischer", "Klaus Jansen"], "summary": "We consider the $\\mathcal{NP}$-hard problem $\\mathrm{P} \\mathbf{\\vert}\n\\mathrm{pmtn, setup=s_i} \\mathbf{\\vert} \\mathrm{C_{\\max}}$, the problem of\nscheduling $n$ jobs, which are divided into $c$ classes, on $m$ identical\nparallel machines while allowing preemption. For each class $i$ of the $c$\nclasses, we are given a setup time $s_i$ that is required to be scheduled\nwhenever a machine switches from processing a job of one class to a job from\nanother class. The goal is to find a schedule that minimizes the makespan.\n  We give a $(4/3+\\varepsilon)$-approximate algorithm with run time in\n$\\mathcal{O}(n^2 \\log(1/\\varepsilon))$. For any $\\varepsilon < 1/6$, this\nimproves upon the previously best known approximation ratio of $3/2$ for this\nproblem.\n  Our main technical contributions are as follows. We first partition any\ninstance into an \"easy\" and a \"hard\" part, such that a $4/3 T$-approximation\nfor the former is easy to compute for some given makespan $T$. We then proceed\nto show our main structural result, namely that there always exists a $4/3\nT$-approximation for any instance that has a solution with makespan $T$, where\nthe hard part has some easy to compute properties. Finally, we obtain an\nalgorithm that computes a $(4/3+\\varepsilon)$-approximation in time n\n$\\mathcal{O}(n^2 \\log(1/\\varepsilon))$ for general instances by computing\nsolutions with the previously shown structural properties.", "published": "2025-08-20T08:37:26+00:00", "updated": "2025-08-20T08:37:26+00:00", "primary_category": "cs.DS", "categories": ["cs.DS"], "pdf_url": "http://arxiv.org/pdf/2508.14528v1"}
{"id": "http://arxiv.org/abs/2508.14527v1", "title": "Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles", "authors": ["Jiangfan Liu", "Yongkang Guo", "Fangzhi Zhong", "Tianyuan Zhang", "Zonglei Jing", "Siyuan Liang", "Jiakai Wang", "Mingchuan Zhang", "Aishan Liu", "Xianglong Liu"], "summary": "The generation of safety-critical scenarios in simulation has become\nincreasingly crucial for safety evaluation in autonomous vehicles prior to road\ndeployment in society. However, current approaches largely rely on predefined\nthreat patterns or rule-based strategies, which limit their ability to expose\ndiverse and unforeseen failure modes. To overcome these, we propose ScenGE, a\nframework that can generate plentiful safety-critical scenarios by reasoning\nnovel adversarial cases and then amplifying them with complex traffic flows.\nGiven a simple prompt of a benign scene, it first performs Meta-Scenario\nGeneration, where a large language model, grounded in structured driving\nknowledge, infers an adversarial agent whose behavior poses a threat that is\nboth plausible and deliberately challenging. This meta-scenario is then\nspecified in executable code for precise in-simulator control. Subsequently,\nComplex Scenario Evolution uses background vehicles to amplify the core threat\nintroduced by Meta-Scenario. It builds an adversarial collaborator graph to\nidentify key agent trajectories for optimization. These perturbations are\ndesigned to simultaneously reduce the ego vehicle's maneuvering space and\ncreate critical occlusions. Extensive experiments conducted on multiple\nreinforcement learning based AV models show that ScenGE uncovers more severe\ncollision cases (+31.96%) on average than SoTA baselines. Additionally, our\nScenGE can be applied to large model based AV systems and deployed on different\nsimulators; we further observe that adversarial training on our scenarios\nimproves the model robustness. Finally, we validate our framework through\nreal-world vehicle tests and human evaluation, confirming that the generated\nscenarios are both plausible and critical. We hope our paper can build up a\ncritical step towards building public trust and ensuring their safe deployment.", "published": "2025-08-20T08:36:57+00:00", "updated": "2025-08-20T08:36:57+00:00", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2508.14527v1"}
{"id": "http://arxiv.org/abs/2508.14523v1", "title": "Great GATsBi: Hybrid, Multimodal, Trajectory Forecasting for Bicycles using Anticipation Mechanism", "authors": ["Kevin Riehl", "Shaimaa K. El-Baklish", "Anastasios Kouvelas", "Michail A. Makridis"], "summary": "Accurate prediction of road user movement is increasingly required by many\napplications ranging from advanced driver assistance systems to autonomous\ndriving, and especially crucial for road safety. Even though most traffic\naccident fatalities account to bicycles, they have received little attention,\nas previous work focused mainly on pedestrians and motorized vehicles. In this\nwork, we present the Great GATsBi, a domain-knowledge-based, hybrid, multimodal\ntrajectory prediction framework for bicycles. The model incorporates both\nphysics-based modeling (inspired by motorized vehicles) and social-based\nmodeling (inspired by pedestrian movements) to explicitly account for the dual\nnature of bicycle movement. The social interactions are modeled with a graph\nattention network, and include decayed historical, but also anticipated, future\ntrajectory data of a bicycles neighborhood, following recent insights from\npsychological and social studies. The results indicate that the proposed\nensemble of physics models -- performing well in the short-term predictions --\nand social models -- performing well in the long-term predictions -- exceeds\nstate-of-the-art performance. We also conducted a controlled mass-cycling\nexperiment to demonstrate the framework's performance when forecasting bicycle\ntrajectories and modeling social interactions with road users.", "published": "2025-08-20T08:31:35+00:00", "updated": "2025-08-20T08:31:35+00:00", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2508.14523v1"}
